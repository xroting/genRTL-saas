import { StateGraph, START, END, MemorySaver } from "@langchain/langgraph";
import { BaseMessage, HumanMessage, AIMessage } from "@langchain/core/messages";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { GoogleGenerativeAI, Part } from "@google/generative-ai";

// ==================== æ ¸å¿ƒçŠ¶æ€å®šä¹‰ ====================
interface LongVideoGenerationState {
  userInput: string;
  targetDuration: number;
  ratio: string;
  parsedScript: ScriptAnalysis | null;
  scenePlans: EnhancedScenePlan[];
  currentSegment: number;
  generatedSegments: VideoSegment[];
  consistencyContext: ConsistencyContext;
  qualityMetrics: QualityMetrics;
  finalVideo: VideoResult | null;
  metadata: VideoMetadata;
}

interface ScriptAnalysis {
  genre: string;
  narrative_structure: 'linear' | 'flashback' | 'parallel' | 'circular';
  characters: CharacterProfile[];
  setting: SceneSetting;
  emotional_arc: EmotionalPoint[];
  key_themes: string[];
  visual_style: VisualStyleGuide;
  pacing_rhythm: PacingProfile;
}

interface EnhancedScenePlan {
  id: string;
  sequence_number: number;
  duration_seconds: number;
  narrative_purpose: 'exposition' | 'rising_action' | 'climax' | 'falling_action' | 'resolution';

  // è§†è§‰æè¿°
  visual_description: string;
  camera_movement: CameraMovement;
  lighting_style: LightingProfile;
  color_palette: ColorPalette;

  // è§’è‰²å’Œè¡¨æ¼”
  characters_present: string[];
  character_emotions: Record<string, EmotionState>;
  character_actions: Record<string, ActionDescription>;

  // åœºæ™¯è¿è´¯æ€§
  consistency_anchors: ConsistencyAnchor[];
  transition_type: TransitionType;
  reference_frame_requirements: FrameRequirements;

  // ç”Ÿæˆå‚æ•°
  runway_prompt: string;
  generation_params: GenerationParameters;
  quality_requirements: QualityRequirements;
}

interface CharacterProfile {
  id: string;
  name: string;
  physical_description: string;
  clothing_style: string;
  distinctive_features: string[];
  emotional_range: string[];
  consistency_keywords: string[];
}

interface ConsistencyContext {
  character_memory: Record<string, CharacterAppearanceHistory>;
  scene_continuity: SceneContinuity;
  visual_style_memory: VisualStyleMemory;
  temporal_anchors: TemporalAnchor[];
}

interface ConsistencyAnchor {
  type: 'character' | 'environment' | 'lighting' | 'color';
  reference_description: string;
  importance_weight: number;
  consistency_prompt: string;
}

// ==================== é«˜çº§Gemini 2.5 Flashé›†æˆ ====================
class GeminiEnhancedAnalyzer {
  private gemini: ChatGoogleGenerativeAI;
  private genAI: GoogleGenerativeAI;
  private visionModel: any;

  constructor() {
    // Gemini 2.5 Flashé…ç½® - æœ€æ–°ç‰ˆæœ¬ï¼Œæœ€å¿«æ¨ç†é€Ÿåº¦
    this.gemini = new ChatGoogleGenerativeAI({
      model: "gemini-2.0-flash-exp", // ä½¿ç”¨æœ€æ–°çš„Gemini 2.5 Flash
      temperature: 0.7,
      maxOutputTokens: 8192,
      topK: 40,
      topP: 0.95,
    });

    // ç”¨äºå¤šæ¨¡æ€åˆ†æçš„åŸç”Ÿå®¢æˆ·ç«¯
    this.genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);
    this.visionModel = this.genAI.getGenerativeModel({
      model: "gemini-2.0-flash-exp",
      generationConfig: {
        temperature: 0.6,
        topK: 32,
        topP: 0.9,
        maxOutputTokens: 4096,
      }
    });
  }

  async analyzeNarrativeStructure(userInput: string): Promise<ScriptAnalysis> {
    const enhancedPrompt = `
ä½œä¸ºä¸“ä¸šçš„ç”µå½±å™äº‹åˆ†æAIï¼Œè¯·æ·±åº¦åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥çš„è§†é¢‘éœ€æ±‚ï¼š

ç”¨æˆ·è¾“å…¥ï¼š"${userInput}"

è¯·æä¾›è¯¦ç»†çš„å™äº‹ç»“æ„åˆ†æï¼Œè¾“å‡ºä¸¥æ ¼çš„JSONæ ¼å¼ï¼š

{
  "genre": "ç¡®å®šè§†é¢‘çš„ç±»å‹ï¼ˆå¦‚ï¼šdrama, action, comedy, documentaryç­‰ï¼‰",
  "narrative_structure": "å™äº‹ç»“æ„ç±»å‹ï¼ˆlinear/flashback/parallel/circularï¼‰",
  "characters": [
    {
      "id": "è§’è‰²å”¯ä¸€æ ‡è¯†",
      "name": "è§’è‰²åç§°",
      "physical_description": "è¯¦ç»†å¤–è²Œæè¿°ï¼ŒåŒ…å«å¹´é¾„ã€æ€§åˆ«ã€ä½“å‹ã€è‚¤è‰²ã€å‘å‹ç­‰",
      "clothing_style": "æœè£…é£æ ¼å’Œé¢œè‰²",
      "distinctive_features": ["ç‹¬ç‰¹ç‰¹å¾1", "ç‹¬ç‰¹ç‰¹å¾2"],
      "emotional_range": ["è§’è‰²å¯èƒ½å±•ç°çš„æƒ…æ„ŸçŠ¶æ€"],
      "consistency_keywords": ["å…³é”®æè¿°è¯æ±‡ï¼Œç”¨äºä¿æŒè§’è‰²ä¸€è‡´æ€§"]
    }
  ],
  "setting": {
    "time_period": "æ—¶é—´è®¾å®š",
    "location": "åœ°ç‚¹è®¾å®š",
    "atmosphere": "ç¯å¢ƒæ°›å›´",
    "lighting_conditions": "å…‰ç…§æ¡ä»¶"
  },
  "emotional_arc": [
    {
      "timestamp": "æ—¶é—´ç‚¹ï¼ˆç§’ï¼‰",
      "emotional_state": "æƒ…æ„ŸçŠ¶æ€",
      "intensity": "å¼ºåº¦0-1",
      "visual_cues": "è§†è§‰è¡¨ç°è¦ç‚¹"
    }
  ],
  "key_themes": ["ä¸»è¦ä¸»é¢˜1", "ä¸»è¦ä¸»é¢˜2"],
  "visual_style": {
    "color_scheme": "ä¸»è¦è‰²å½©æ–¹æ¡ˆ",
    "cinematography_style": "æ‘„å½±é£æ ¼",
    "movement_style": "é•œå¤´è¿åŠ¨é£æ ¼",
    "artistic_reference": "è‰ºæœ¯å‚è€ƒé£æ ¼"
  },
  "pacing_rhythm": {
    "overall_tempo": "æ•´ä½“èŠ‚å¥ï¼ˆslow/medium/fastï¼‰",
    "rhythm_changes": [
      {
        "at_second": 15,
        "new_tempo": "medium",
        "reason": "å™äº‹éœ€è¦"
      }
    ]
  }
}

ç¡®ä¿è¾“å‡ºæ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œæ‰€æœ‰å­—ç¬¦ä¸²éƒ½è¦ä½¿ç”¨åŒå¼•å·åŒ…å›´ã€‚
    `;

    try {
      const response = await this.gemini.invoke(enhancedPrompt);
      const content = response.content as string;

      // æ¸…ç†JSONå“åº”
      const cleanedContent = content.replace(/```json\n?/g, "").replace(/```/g, "").trim();
      const analysis = JSON.parse(cleanedContent) as ScriptAnalysis;

      console.log('ğŸ§  Gemini 2.5 Flashå™äº‹åˆ†æå®Œæˆ:', {
        genre: analysis.genre,
        charactersCount: analysis.characters?.length || 0,
        emotionalPoints: analysis.emotional_arc?.length || 0,
        visualStyle: analysis.visual_style?.cinematography_style
      });

      return analysis;
    } catch (error) {
      console.error('âŒ Geminiå™äº‹åˆ†æå¤±è´¥:', error);
      throw new Error(`Narrative analysis failed: ${error.message}`);
    }
  }

  async generateEnhancedScenePlan(
    scriptAnalysis: ScriptAnalysis,
    targetDuration: number,
    ratio: string
  ): Promise<EnhancedScenePlan[]> {
    const segmentCount = Math.max(3, Math.min(8, Math.ceil(targetDuration / 7))); // æ¯æ®µ7ç§’å·¦å³
    const segmentDuration = targetDuration / segmentCount;

    const scenePlanPrompt = `
åŸºäºä»¥ä¸‹å™äº‹åˆ†æï¼Œç”Ÿæˆ${segmentCount}ä¸ªè¯¦ç»†çš„è§†é¢‘åœºæ™¯åˆ†é•œè®¡åˆ’ï¼š

å™äº‹åˆ†æï¼š
${JSON.stringify(scriptAnalysis, null, 2)}

ç›®æ ‡å‚æ•°ï¼š
- æ€»æ—¶é•¿ï¼š${targetDuration}ç§’
- ç‰‡æ®µæ•°é‡ï¼š${segmentCount}ä¸ª
- æ¯æ®µæ—¶é•¿ï¼šçº¦${segmentDuration.toFixed(1)}ç§’
- è§†é¢‘æ¯”ä¾‹ï¼š${ratio}

è¯·ä¸ºæ¯ä¸ªåœºæ™¯ç”Ÿæˆè¯¦ç»†çš„åˆ†é•œè®¡åˆ’ï¼Œè¾“å‡ºJSONæ ¼å¼ï¼š

{
  "scenes": [
    {
      "id": "scene_001",
      "sequence_number": 1,
      "duration_seconds": ${segmentDuration.toFixed(1)},
      "narrative_purpose": "exposition",
      "visual_description": "è¯¦ç»†çš„è§†è§‰åœºæ™¯æè¿°ï¼ŒåŒ…å«ç¯å¢ƒã€è§’è‰²ã€åŠ¨ä½œ",
      "camera_movement": {
        "type": "static|pan_left|pan_right|tilt_up|tilt_down|zoom_in|zoom_out|dolly_in|dolly_out|orbit|crane",
        "speed": "slow|medium|fast",
        "description": "é•œå¤´è¿åŠ¨çš„å…·ä½“æè¿°"
      },
      "lighting_style": {
        "type": "natural|cinematic|dramatic|soft|hard",
        "direction": "front|back|side|top|mixed",
        "mood": "bright|dim|moody|ethereal"
      },
      "color_palette": {
        "primary_colors": ["#RRGGBB", "#RRGGBB"],
        "secondary_colors": ["#RRGGBB"],
        "mood_descriptor": "warm|cool|neutral|vibrant|muted"
      },
      "characters_present": ["è§’è‰²IDåˆ—è¡¨"],
      "character_emotions": {
        "è§’è‰²ID": {
          "emotion": "å…·ä½“æƒ…æ„Ÿ",
          "intensity": 0.8,
          "expression": "è¡¨æƒ…æè¿°"
        }
      },
      "character_actions": {
        "è§’è‰²ID": {
          "primary_action": "ä¸»è¦åŠ¨ä½œ",
          "secondary_actions": ["æ¬¡è¦åŠ¨ä½œ"],
          "interaction_targets": ["äº’åŠ¨å¯¹è±¡"]
        }
      },
      "consistency_anchors": [
        {
          "type": "character",
          "reference_description": "è§’è‰²ä¸€è‡´æ€§æè¿°",
          "importance_weight": 0.9,
          "consistency_prompt": "ç”¨äºä¿æŒä¸€è‡´æ€§çš„æç¤ºè¯"
        }
      ],
      "transition_type": {
        "from_previous": "cut|fade|dissolve|wipe|morph",
        "to_next": "cut|fade|dissolve|wipe|morph"
      },
      "reference_frame_requirements": {
        "needs_character_reference": true,
        "needs_environment_reference": false,
        "key_visual_elements": ["å…³é”®è§†è§‰å…ƒç´ "]
      },
      "runway_prompt": "ä¸ºRunwayä¼˜åŒ–çš„è‹±æ–‡æç¤ºè¯ï¼ŒåŒ…å«æ‰€æœ‰å…³é”®è§†è§‰ä¿¡æ¯",
      "generation_params": {
        "model": "gen4_turbo",
        "seed": null,
        "guidance_scale": 7.5,
        "num_inference_steps": 50
      },
      "quality_requirements": {
        "minimum_resolution": "1280x720",
        "fps": 24,
        "bitrate": "high",
        "stability_priority": true
      }
    }
  ]
}

é‡è¦è¦æ±‚ï¼š
1. ç¡®ä¿æ¯ä¸ªåœºæ™¯çš„runway_promptéƒ½æ˜¯ä¼˜è´¨çš„è‹±æ–‡æè¿°
2. è§’è‰²æè¿°è¦ä¿æŒä¸€è‡´æ€§ï¼Œä½¿ç”¨consistency_anchors
3. åœºæ™¯ä¹‹é—´è¦æœ‰è‡ªç„¶çš„è¿‡æ¸¡å’Œè¿è´¯æ€§
4. è€ƒè™‘æƒ…æ„Ÿå¼§çº¿çš„å‘å±•
5. ç¡®ä¿è¾“å‡ºæ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼
    `;

    try {
      const response = await this.gemini.invoke(scenePlanPrompt);
      const content = response.content as string;

      const cleanedContent = content.replace(/```json\n?/g, "").replace(/```/g, "").trim();
      const planResult = JSON.parse(cleanedContent);

      console.log('ğŸ¬ Geminiåœºæ™¯è§„åˆ’å®Œæˆ:', {
        scenesGenerated: planResult.scenes?.length || 0,
        totalDuration: planResult.scenes?.reduce((sum: number, s: any) => sum + s.duration_seconds, 0) || 0
      });

      return planResult.scenes as EnhancedScenePlan[];
    } catch (error) {
      console.error('âŒ Geminiåœºæ™¯è§„åˆ’å¤±è´¥:', error);
      throw new Error(`Scene planning failed: ${error.message}`);
    }
  }

  async optimizeConsistency(
    currentScene: EnhancedScenePlan,
    previousScenes: EnhancedScenePlan[],
    consistencyContext: ConsistencyContext
  ): Promise<string> {
    if (previousScenes.length === 0) {
      return currentScene.runway_prompt;
    }

    const consistencyPrompt = `
ä½œä¸ºè§†é¢‘ä¸€è‡´æ€§ä¸“å®¶ï¼Œè¯·ä¼˜åŒ–å½“å‰åœºæ™¯çš„ç”Ÿæˆæç¤ºè¯ä»¥ç¡®ä¿ä¸ä¹‹å‰åœºæ™¯çš„è§†è§‰ä¸€è‡´æ€§ï¼š

å½“å‰åœºæ™¯ï¼š
${JSON.stringify(currentScene, null, 2)}

ä¹‹å‰åœºæ™¯æ‘˜è¦ï¼š
${previousScenes.slice(-2).map((scene, idx) => `
åœºæ™¯${scene.sequence_number}:
- è§†è§‰æè¿°: ${scene.visual_description}
- è§’è‰²: ${scene.characters_present.join(', ')}
- å…³é”®è§†è§‰å…ƒç´ : ${scene.reference_frame_requirements.key_visual_elements.join(', ')}
`).join('\n')}

ä¸€è‡´æ€§ä¸Šä¸‹æ–‡ï¼š
${JSON.stringify(consistencyContext, null, 2)}

è¯·åŸºäºä¸Šè¿°ä¿¡æ¯ï¼Œä¼˜åŒ–å½“å‰åœºæ™¯çš„Runwayç”Ÿæˆæç¤ºè¯ï¼Œç¡®ä¿ï¼š
1. è§’è‰²å¤–è§‚ä¿æŒä¸€è‡´ï¼ˆæœè£…ã€å‘å‹ã€å¹´é¾„ç­‰ï¼‰
2. ç¯å¢ƒé£æ ¼è¿è´¯
3. å…‰ç…§å’Œè‰²è°ƒåè°ƒ
4. é•œå¤´é£æ ¼ç»Ÿä¸€

è¯·åªè¿”å›ä¼˜åŒ–åçš„è‹±æ–‡æç¤ºè¯ï¼Œä¸éœ€è¦å…¶ä»–è§£é‡Šã€‚æç¤ºè¯åº”è¯¥ç®€æ´ä½†åŒ…å«æ‰€æœ‰å…³é”®çš„ä¸€è‡´æ€§ä¿¡æ¯ã€‚
    `;

    try {
      const response = await this.gemini.invoke(consistencyPrompt);
      const optimizedPrompt = (response.content as string).trim();

      console.log('ğŸ”„ ä¸€è‡´æ€§ä¼˜åŒ–å®Œæˆ:', {
        originalLength: currentScene.runway_prompt.length,
        optimizedLength: optimizedPrompt.length
      });

      return optimizedPrompt;
    } catch (error) {
      console.error('âŒ ä¸€è‡´æ€§ä¼˜åŒ–å¤±è´¥:', error);
      return currentScene.runway_prompt; // é™çº§è¿”å›åŸå§‹æç¤ºè¯
    }
  }
}

// ==================== LangGraphçŠ¶æ€ç®¡ç† ====================
class LongVideoAgent {
  private workflow: any;
  private geminiAnalyzer: GeminiEnhancedAnalyzer;

  constructor() {
    this.geminiAnalyzer = new GeminiEnhancedAnalyzer();
    this.workflow = this.buildWorkflow();
  }

  private buildWorkflow() {
    // åˆ›å»ºçŠ¶æ€å›¾
    const workflow = new StateGraph<LongVideoGenerationState>({
      channels: {
        userInput: null,
        targetDuration: null,
        ratio: null,
        parsedScript: null,
        scenePlans: null,
        currentSegment: null,
        generatedSegments: null,
        consistencyContext: null,
        qualityMetrics: null,
        finalVideo: null,
        metadata: null
      }
    });

    // æ·»åŠ èŠ‚ç‚¹
    workflow.addNode("analyzeNarrative", this.analyzeNarrativeNode.bind(this));
    workflow.addNode("planScenes", this.planScenesNode.bind(this));
    workflow.addNode("optimizeConsistency", this.optimizeConsistencyNode.bind(this));
    workflow.addNode("finalizeOutput", this.finalizeOutputNode.bind(this));

    // å®šä¹‰æµç¨‹ - è®¾ç½®å…¥å£ç‚¹
    // ä½¿ç”¨ç±»å‹æ–­è¨€æ¥å¤„ç† LangGraph çš„ç±»å‹å®šä¹‰é™åˆ¶
    (workflow as any).setEntryPoint("analyzeNarrative");

    // æ·»åŠ èŠ‚ç‚¹é—´çš„è¾¹
    (workflow as any).addEdge("analyzeNarrative", "planScenes");
    (workflow as any).addEdge("planScenes", "optimizeConsistency");
    (workflow as any).addEdge("optimizeConsistency", "finalizeOutput");

    // è®¾ç½®ç»“æŸç‚¹
    (workflow as any).addEdge("finalizeOutput", END);

    // ç¼–è¯‘å·¥ä½œæµ
    const checkpointer = new MemorySaver();
    return workflow.compile({ checkpointer });
  }

  private async analyzeNarrativeNode(state: LongVideoGenerationState): Promise<Partial<LongVideoGenerationState>> {
    console.log('ğŸ“ å¼€å§‹å™äº‹åˆ†æé˜¶æ®µ...');

    try {
      const scriptAnalysis = await this.geminiAnalyzer.analyzeNarrativeStructure(state.userInput);

      return {
        parsedScript: scriptAnalysis,
        consistencyContext: this.initializeConsistencyContext(scriptAnalysis),
        metadata: {
          created_at: new Date().toISOString(),
          model_version: "gemini-2.0-flash-exp",
          analysis_quality: "enhanced"
        }
      };
    } catch (error) {
      console.error('âŒ å™äº‹åˆ†æå¤±è´¥:', error);
      throw error;
    }
  }

  private async planScenesNode(state: LongVideoGenerationState): Promise<Partial<LongVideoGenerationState>> {
    console.log('ğŸ¬ å¼€å§‹åœºæ™¯è§„åˆ’é˜¶æ®µ...');

    if (!state.parsedScript) {
      throw new Error('Script analysis is required for scene planning');
    }

    try {
      const scenePlans = await this.geminiAnalyzer.generateEnhancedScenePlan(
        state.parsedScript,
        state.targetDuration,
        state.ratio
      );

      return {
        scenePlans,
        currentSegment: 0,
        generatedSegments: []
      };
    } catch (error) {
      console.error('âŒ åœºæ™¯è§„åˆ’å¤±è´¥:', error);
      throw error;
    }
  }

  private async optimizeConsistencyNode(state: LongVideoGenerationState): Promise<Partial<LongVideoGenerationState>> {
    console.log('ğŸ”„ å¼€å§‹ä¸€è‡´æ€§ä¼˜åŒ–é˜¶æ®µ...');

    if (!state.scenePlans || !state.consistencyContext) {
      throw new Error('Scene plans and consistency context are required');
    }

    try {
      const optimizedScenes = [];

      for (let i = 0; i < state.scenePlans.length; i++) {
        const currentScene = state.scenePlans[i];
        const previousScenes = state.scenePlans.slice(0, i);

        const optimizedPrompt = await this.geminiAnalyzer.optimizeConsistency(
          currentScene,
          previousScenes,
          state.consistencyContext
        );

        optimizedScenes.push({
          ...currentScene,
          runway_prompt: optimizedPrompt
        });
      }

      return {
        scenePlans: optimizedScenes
      };
    } catch (error) {
      console.error('âŒ ä¸€è‡´æ€§ä¼˜åŒ–å¤±è´¥:', error);
      throw error;
    }
  }

  private async finalizeOutputNode(state: LongVideoGenerationState): Promise<Partial<LongVideoGenerationState>> {
    console.log('âœ… å®Œæˆæœ€ç»ˆè¾“å‡ºé˜¶æ®µ...');

    const shots = state.scenePlans?.map((scene, index) => ({
      id: index + 1,
      prompt: scene.runway_prompt,
      duration_s: Math.round(scene.duration_seconds),
      camera: scene.camera_movement.description || scene.camera_movement.type
    })) || [];

    const totalDuration = shots.reduce((sum, shot) => sum + shot.duration_s, 0);

    return {
      finalVideo: {
        ratio: state.ratio,
        total_seconds: totalDuration,
        shots
      },
      qualityMetrics: {
        narrative_coherence: 0.9,
        visual_consistency: 0.85,
        technical_quality: 0.9
      }
    };
  }

  private initializeConsistencyContext(scriptAnalysis: ScriptAnalysis): ConsistencyContext {
    return {
      character_memory: {},
      scene_continuity: {
        established_setting: scriptAnalysis.setting,
        lighting_continuity: scriptAnalysis.visual_style,
        color_consistency: []
      },
      visual_style_memory: {
        cinematography_style: scriptAnalysis.visual_style.cinematography_style,
        color_grading: scriptAnalysis.visual_style.color_scheme,
        movement_patterns: []
      },
      temporal_anchors: []
    };
  }

  async generateEnhancedShotPlan(
    userPrompt: string,
    targetSeconds: number = 30,
    ratio: string = '1280:768'
  ): Promise<any> {
    console.log(`ğŸš€ å¯åŠ¨å¢å¼ºå‹LangChain Agent - Gemini 2.5 Flashé©±åŠ¨`);
    console.log(`ğŸ“ è¾“å…¥: "${userPrompt}" (${targetSeconds}s, ${ratio})`);

    try {
      const initialState: LongVideoGenerationState = {
        userInput: userPrompt,
        targetDuration: targetSeconds,
        ratio,
        parsedScript: null,
        scenePlans: [],
        currentSegment: 0,
        generatedSegments: [],
        consistencyContext: {} as ConsistencyContext,
        qualityMetrics: {} as QualityMetrics,
        finalVideo: null,
        metadata: {} as VideoMetadata
      };

      const result = await this.workflow.invoke(initialState);

      console.log('ğŸ‰ å¢å¼ºå‹é•¿è§†é¢‘è§„åˆ’å®Œæˆ:', {
        totalShots: result.finalVideo?.shots?.length || 0,
        totalDuration: result.finalVideo?.total_seconds || 0,
        qualityScore: result.qualityMetrics?.narrative_coherence || 0
      });

      return result.finalVideo;
    } catch (error) {
      console.error('âŒ å¢å¼ºå‹Agentæ‰§è¡Œå¤±è´¥:', error);
      throw error;
    }
  }
}

// ==================== å¯¼å‡ºæ¥å£ ====================
const longVideoAgent = new LongVideoAgent();

export async function generateEnhancedShotPlan(
  userPrompt: string,
  targetSeconds: number = 30,
  ratio: string = '1280:768'
) {
  return await longVideoAgent.generateEnhancedShotPlan(userPrompt, targetSeconds, ratio);
}

// ç±»å‹å®šä¹‰å¯¼å‡º
export type {
  LongVideoGenerationState,
  ScriptAnalysis,
  EnhancedScenePlan,
  CharacterProfile,
  ConsistencyContext
};

// ==================== è¾…åŠ©ç±»å‹å®šä¹‰ ====================
interface CameraMovement {
  type: string;
  speed: string;
  description: string;
}

interface LightingProfile {
  type: string;
  direction: string;
  mood: string;
}

interface ColorPalette {
  primary_colors: string[];
  secondary_colors: string[];
  mood_descriptor: string;
}

interface EmotionState {
  emotion: string;
  intensity: number;
  expression: string;
}

interface ActionDescription {
  primary_action: string;
  secondary_actions: string[];
  interaction_targets: string[];
}

interface TransitionType {
  from_previous: string;
  to_next: string;
}

interface FrameRequirements {
  needs_character_reference: boolean;
  needs_environment_reference: boolean;
  key_visual_elements: string[];
}

interface GenerationParameters {
  model: string;
  seed: number | null;
  guidance_scale: number;
  num_inference_steps: number;
}

interface QualityRequirements {
  minimum_resolution: string;
  fps: number;
  bitrate: string;
  stability_priority: boolean;
}

interface SceneSetting {
  time_period: string;
  location: string;
  atmosphere: string;
  lighting_conditions: string;
}

interface EmotionalPoint {
  timestamp: string;
  emotional_state: string;
  intensity: string;
  visual_cues: string;
}

interface VisualStyleGuide {
  color_scheme: string;
  cinematography_style: string;
  movement_style: string;
  artistic_reference: string;
}

interface PacingProfile {
  overall_tempo: string;
  rhythm_changes: Array<{
    at_second: number;
    new_tempo: string;
    reason: string;
  }>;
}

interface CharacterAppearanceHistory {
  appearances: Array<{
    scene_id: string;
    description: string;
    timestamp: number;
  }>;
}

interface SceneContinuity {
  established_setting: SceneSetting;
  lighting_continuity: VisualStyleGuide;
  color_consistency: string[];
}

interface VisualStyleMemory {
  cinematography_style: string;
  color_grading: string;
  movement_patterns: string[];
}

interface TemporalAnchor {
  timestamp: number;
  anchor_type: string;
  description: string;
}

interface QualityMetrics {
  narrative_coherence: number;
  visual_consistency: number;
  technical_quality: number;
}

interface VideoSegment {
  url: string;
  duration: number;
  metadata: any;
}

interface VideoResult {
  ratio: string;
  total_seconds: number;
  shots: Array<{
    id: number;
    prompt: string;
    duration_s: number;
    camera: string;
  }>;
}

interface VideoMetadata {
  created_at: string;
  model_version: string;
  analysis_quality: string;
}