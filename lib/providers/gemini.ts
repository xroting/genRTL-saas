import { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } from "@google/generative-ai";
import { putAndGetUrl, putAndGetPublicUrl } from "@/lib/storage";
import crypto from "crypto";

// åˆå§‹åŒ–Geminiå®¢æˆ·ç«¯
if (!process.env.GEMINI_API_KEY) {
  throw new Error("GEMINI_API_KEY environment variable is not set");
}
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

export async function generateImageGemini(prompt: string, referenceImageUrl?: string, referenceImageUrl2?: string) {
  console.log("ğŸ¤– Using Gemini 2.5 Flash Image (Nano Banana) for image generation");
  console.log("ğŸ¨ Starting Gemini image generation:", {
    prompt,
    hasReferenceImage: !!referenceImageUrl,
    hasSecondReferenceImage: !!referenceImageUrl2
  });

  try {
    // å°è¯•ä½¿ç”¨ä¸åŒçš„æ¨¡å‹è¿›è¡Œå›¾ç‰‡ç”Ÿæˆ
    let model;
    let modelName = "gemini-2.5-flash-image-preview";
    
    try {
      model = genAI.getGenerativeModel({
        model: modelName,
        generationConfig: {
          temperature: 0.8,
          topP: 0.9,
          topK: 40,
          maxOutputTokens: 1290, // æ¯å¼ å›¾ç‰‡1290 tokens
        }
      });
    } catch (modelError) {
      console.log("âš ï¸ Primary model failed, trying alternative model...");
      modelName = "gemini-2.5-flash";
      model = genAI.getGenerativeModel({
        model: modelName,
        generationConfig: {
          temperature: 0.8,
          topP: 0.9,
          topK: 40,
          maxOutputTokens: 1290,
        }
      });
    }
    
    console.log("ğŸ”§ Model configuration:", {
      modelName,
      temperature: 0.8,
      maxOutputTokens: 1290
    });

    // æ„å»ºå†…å®¹æ•°ç»„
    const contents: any[] = [];

    // å¤„ç†å‚è€ƒå›¾ç‰‡
    if (referenceImageUrl && referenceImageUrl2) {
      // åŒå›¾ç‰‡æ¨¡å¼ï¼šå¤„ç†ä¸¤å¼ å‚è€ƒå›¾ç‰‡è¿›è¡Œåˆæˆ
      console.log("ğŸ–¼ï¸ğŸ–¼ï¸ Adding two reference images for anime merge/composition");

      // ä¸‹è½½ç¬¬ä¸€å¼ å›¾ç‰‡
      const imageResponse1 = await fetch(referenceImageUrl);
      if (!imageResponse1.ok) {
        throw new Error(`Failed to fetch first reference image: ${imageResponse1.statusText}`);
      }

      const imageBuffer1 = await imageResponse1.arrayBuffer();
      const base64Image1 = Buffer.from(imageBuffer1).toString('base64');
      const mimeType1 = imageResponse1.headers.get('content-type') || 'image/png';

      contents.push({
        inlineData: {
          data: base64Image1,
          mimeType: mimeType1
        }
      });

      // ä¸‹è½½ç¬¬äºŒå¼ å›¾ç‰‡
      const imageResponse2 = await fetch(referenceImageUrl2);
      if (!imageResponse2.ok) {
        throw new Error(`Failed to fetch second reference image: ${imageResponse2.statusText}`);
      }

      const imageBuffer2 = await imageResponse2.arrayBuffer();
      const base64Image2 = Buffer.from(imageBuffer2).toString('base64');
      const mimeType2 = imageResponse2.headers.get('content-type') || 'image/png';

      contents.push({
        inlineData: {
          data: base64Image2,
          mimeType: mimeType2
        }
      });

      // ä¸ºåŒå›¾ç‰‡åˆæˆæ·»åŠ æç¤ºè¯
      contents.push({
        text: prompt
      });
    } else if (referenceImageUrl) {
      // å•å›¾ç‰‡æ¨¡å¼ï¼šå¤„ç†ä¸€å¼ å‚è€ƒå›¾ç‰‡
      console.log("ğŸ–¼ï¸ Adding reference image for image editing/composition");

      // ä¸‹è½½å‚è€ƒå›¾ç‰‡å¹¶è½¬æ¢ä¸ºBase64
      const imageResponse = await fetch(referenceImageUrl);
      if (!imageResponse.ok) {
        throw new Error(`Failed to fetch reference image: ${imageResponse.statusText}`);
      }

      const imageBuffer = await imageResponse.arrayBuffer();
      const base64Image = Buffer.from(imageBuffer).toString('base64');
      const mimeType = imageResponse.headers.get('content-type') || 'image/png';

      contents.push({
        inlineData: {
          data: base64Image,
          mimeType: mimeType
        }
      });

      // ä¸ºå›¾åƒç¼–è¾‘æ·»åŠ æç¤ºè¯
      contents.push({
        text: prompt
      });
    } else {
      // çº¯æ–‡æœ¬ç”Ÿæˆå›¾ç‰‡
      contents.push({
        text: prompt
      });
    }

    console.log("ğŸ“¤ Sending request to Gemini 2.5 Flash Image API");

    // å‘é€è¯·æ±‚åˆ°Gemini API
    const result = await model.generateContent(contents);
    const response = await result.response;

    // æ£€æŸ¥å“åº”
    const candidates = response.candidates;
    if (!candidates || candidates.length === 0) {
      throw new Error("No image generated by Gemini");
    }

    console.log("ğŸ” Gemini response candidates:", candidates.length);

    // è·å–ç”Ÿæˆçš„å›¾ç‰‡
    const candidate = candidates[0];
    
    // æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
    console.log("ğŸ” Gemini response structure:", JSON.stringify({
      hasContent: !!candidate.content,
      hasParts: !!candidate.content?.parts,
      partsLength: candidate.content?.parts?.length || 0,
      partsStructure: candidate.content?.parts?.map((part: any) => ({
        hasText: !!part.text,
        hasInlineData: !!part.inlineData,
        hasExectuableCode: !!part.executableCode,
        hasCodeExecutionResult: !!part.codeExecutionResult,
        keys: Object.keys(part)
      })) || []
    }, null, 2));
    
    if (!candidate.content || !candidate.content.parts || candidate.content.parts.length === 0) {
      console.log("âŒ No content or parts found in candidate:", JSON.stringify(candidate, null, 2));
      throw new Error("No image content in Gemini response");
    }

    // æŸ¥æ‰¾å›¾ç‰‡éƒ¨åˆ†
    const imagePart = candidate.content.parts.find((part: any) => part.inlineData);
    if (!imagePart || !imagePart.inlineData) {
      console.log("âŒ No inline data found, response parts:", JSON.stringify(candidate.content.parts, null, 2));
      throw new Error("No image data found in Gemini response");
    }

    console.log("ğŸ¯ Gemini generated image successfully");

    // è§£ç Base64å›¾ç‰‡æ•°æ®
    const imageData = imagePart.inlineData.data;
    const mimeType = imagePart.inlineData.mimeType || "image/png";

    // è½¬æ¢ä¸ºUint8Array
    const imageBuffer = Buffer.from(imageData, 'base64');
    const bytes = new Uint8Array(imageBuffer);

    console.log("ğŸ’¾ Uploading generated image to storage, size:", bytes.length, "bytes");

    // å­˜å‚¨åˆ°Supabase Storage - ä½¿ç”¨ä¼˜åŒ–çš„å…¬å…±URLç‰ˆæœ¬æé«˜ä¸Šä¼ é€Ÿåº¦
    const fileName = `gemini/${crypto.randomUUID()}.${mimeType.includes('jpeg') ? 'jpg' : 'png'}`;
    const url = await putAndGetPublicUrl(fileName, bytes, mimeType);

    console.log("âœ… Gemini image generation completed, URL:", url);

    return {
      url: url,
      optimizedPrompt: prompt
    };

  } catch (error) {
    console.error("âŒ Gemini image generation failed:", error);
    const errorMessage = error instanceof Error ? error.message : String(error);
    throw new Error(`Geminiå›¾ç‰‡ç”Ÿæˆå¤±è´¥: ${errorMessage}`);
  }
}


/**
 * ä½¿ç”¨Geminiç”Ÿæˆç»“æ„åŒ–çš„é•œå¤´è§„åˆ’JSON
 */
export async function generateShotPlanWithGemini(
  userPrompt: string,
  targetSeconds: number = 30,
  ratio: string = '1280:768'
): Promise<any> {
  console.log(`ğŸ¬ Generating shot plan with Gemini for: "${userPrompt}" (${targetSeconds}s, ${ratio})`);

  // é‡è¯•é€»è¾‘ï¼šå¤„ç†503æœåŠ¡è¿‡è½½é”™è¯¯
  const maxRetries = 3;
  let lastError: any;

  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      if (attempt > 1) {
        const waitTime = Math.min(1000 * Math.pow(2, attempt - 1), 10000); // æŒ‡æ•°é€€é¿ï¼Œæœ€å¤š10ç§’
        console.log(`â³ Retry attempt ${attempt}/${maxRetries}, waiting ${waitTime}ms...`);
        await new Promise(resolve => setTimeout(resolve, waitTime));
      }

      const model = genAI.getGenerativeModel({
        model: "gemini-2.5-flash", // ä½¿ç”¨æœ€æ–°çš„Geminiæ¨¡å‹
        generationConfig: {
          temperature: 0.7,
          topP: 0.8,
          topK: 40,
          maxOutputTokens: 4096, // å¢åŠ è¾“å‡ºé•¿åº¦é™åˆ¶
          responseMimeType: "application/json", // å¼ºåˆ¶è¿”å›JSONæ ¼å¼
        },
        safetySettings: [
          {
            category: HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold: HarmBlockThreshold.BLOCK_NONE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold: HarmBlockThreshold.BLOCK_NONE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
            threshold: HarmBlockThreshold.BLOCK_NONE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold: HarmBlockThreshold.BLOCK_NONE,
          },
        ],
      });
        const systemPrompt = `You are a professional cinematographer specializing in commercial advertising. Break down the user's high-level prompt into coherent, flowing shot sequences that tell a unified story.

CRITICAL REQUIREMENTS FOR VIDEO CONTINUITY:
1. VEO 3.1 generates 8-second video segments and uses VIDEO EXTENSION for continuity
2. Each shot CONTINUES from the previous shot's ending frame - NOT independent scenes
3. Shots must flow naturally: same character, same outfit, same location, continuous action
4. Think of it as ONE continuous video split into 8-second chunks, NOT separate scenes

CHARACTER & OBJECT CONSISTENCY:
5. Extract the MAIN CHARACTER description from user prompt (age, gender, appearance, clothing)
6. Extract the MAIN OBJECT/PRODUCT description (detailed visual features, color, style)
7. Use the EXACT SAME character and object description in EVERY shot prompt
8. Focus on camera movement and action progression, NOT repeating character appearance
9. For product advertising: ensure the product is VISIBLE and RECOGNIZABLE in every shot

SHOT PLANNING PRINCIPLES:
10. Create a CONTINUOUS narrative flow: Shot 1 â†’ Shot 2 â†’ Shot 3 (seamless transitions)
11. Use smooth camera movements: slow pan, gentle zoom, tracking shot, rotating camera
12. Maintain spatial continuity: if character is on the left in Shot 1, keep them on the left in Shot 2
13. Progress the story: Opening â†’ Product showcase â†’ Detail close-up â†’ Emotional finale
14. Each shot should feel like the NEXT moment, not a new scene

TECHNICAL CONSTRAINTS:
15. ALL shot prompts MUST be in English for VEO 3.1 compatibility
16. Keep prompts simple and direct (max 40 words per shot)
17. Use realistic, grounded descriptions (avoid "magical", "spiritual", "mystical", "ethereal")
18. Use basic camera terms: "close-up", "medium shot", "wide shot", "tracking", "static"
19. Total duration should approach target_seconds

EXAMPLE for jewelry ad:
Shot 1: "Close-up of a young woman's hand gently touching an elegant diamond necklace on her neck, soft studio lighting, white background"
Shot 2: "The camera slowly pulls back, revealing the woman's face as she smiles softly, still wearing the same diamond necklace, white background"
Shot 3: "Medium shot of the woman turning her head slightly left, the diamond necklace catches light and sparkles, white background"
Shot 4: "The woman looks directly at camera with a confident smile, the diamond necklace prominently displayed, white background"

Output strictly in the following JSON format with NO other text:

{
  "ratio": "${ratio}",
  "total_seconds": ${targetSeconds},
  "shots": [
    {
      "id": 1,
      "prompt": "Concise but detailed English description of the first shot",
      "duration_s": 10,
      "camera": "static"
    }
  ]
}`;

    const userInput = `User Prompt: ${userPrompt}
Target Duration (seconds): ${targetSeconds}
Aspect Ratio: ${ratio}

INSTRUCTIONS:
1. Identify the MAIN CHARACTER (person/model) from the user prompt - extract their appearance details
2. Identify the MAIN PRODUCT/OBJECT (jewelry, clothing, item) - extract its visual features
3. Create a shot sequence where:
   - Every shot includes the SAME character and SAME product
   - Each shot continues naturally from the previous one (like a single continuous video)
   - Camera moves smoothly to show different angles and details
   - Product is always visible and recognizable
4. Remember: ALL shot descriptions must be in English.

Please break down this prompt into multiple coherent shots that flow together seamlessly.`;

    const result = await model.generateContent([
      { text: systemPrompt },
      { text: userInput }
    ]);

    const response = await result.response;

    // æ£€æŸ¥å®‰å…¨è¿‡æ»¤å’Œé˜»æ­¢åŸå› 
    if (response.promptFeedback?.blockReason) {
      console.error('âŒ Gemini blocked request:', response.promptFeedback.blockReason);
      throw new Error(`Geminiå®‰å…¨è¿‡æ»¤æ‹¦æˆª: ${response.promptFeedback.blockReason}`);
    }

    // æ£€æŸ¥å€™é€‰å“åº”
    if (!response.candidates || response.candidates.length === 0) {
      console.error('âŒ No candidates in Gemini response');
      throw new Error('Geminiæ²¡æœ‰è¿”å›ä»»ä½•å€™é€‰ç»“æœ');
    }

    const candidate = response.candidates[0];

    // æ£€æŸ¥å®ŒæˆåŸå› 
    if (candidate.finishReason && candidate.finishReason !== 'STOP') {
      console.warn(`âš ï¸ Gemini finish reason: ${candidate.finishReason}`);
      if (candidate.finishReason === 'SAFETY') {
        throw new Error('Geminiå› å®‰å…¨åŸå› åœæ­¢ç”Ÿæˆ');
      }
    }

    const text = response.text();

    console.log('ğŸ¤– Gemini raw response length:', text.length);
    console.log('ğŸ¤– Gemini raw response preview:', text.substring(0, 500));

    // æ£€æŸ¥æ˜¯å¦æœ‰å“åº”
    if (!text || text.trim().length === 0) {
      console.error('âŒ Gemini returned empty response');
      console.error('Finish reason:', candidate.finishReason);
      console.error('Safety ratings:', JSON.stringify(candidate.safetyRatings, null, 2));
      throw new Error('Geminiè¿”å›ç©ºå“åº”ï¼Œå¯èƒ½æ˜¯å®‰å…¨è¿‡æ»¤æˆ–APIé™åˆ¶');
    }

    // å°è¯•è§£æJSON
    let plan;
    try {
      // ç”±äºè®¾ç½®äº† responseMimeType: "application/json"ï¼Œå“åº”åº”è¯¥å·²ç»æ˜¯çº¯JSON
      // ä½†ä»ç„¶æ¸…ç†å¯èƒ½çš„markdownä»£ç å—æ ‡è®°ï¼ˆä»¥é˜²ä¸‡ä¸€ï¼‰
      let cleanText = text.replace(/```json\s*|\s*```/g, '').trim();

      // å†æ¬¡æ£€æŸ¥æ¸…ç†åçš„æ–‡æœ¬
      if (!cleanText || cleanText.length === 0) {
        throw new Error('æ¸…ç†åçš„æ–‡æœ¬ä¸ºç©º');
      }

      console.log('ğŸ“ Attempting to parse JSON, length:', cleanText.length);

      // ç›´æ¥å°è¯•è§£æ
      try {
        plan = JSON.parse(cleanText);
        console.log('âœ… JSON parsed successfully');
      } catch (parseError) {
        console.error('âŒ Initial JSON parse failed:', parseError);

        // æ£€æŸ¥JSONæ˜¯å¦è¢«æˆªæ–­ï¼Œå¦‚æœæ˜¯åˆ™å°è¯•ä¿®å¤
        if (!cleanText.endsWith('}') && !cleanText.endsWith(']}')) {
          console.warn('âš ï¸ Detected truncated JSON, attempting to fix...');

          // æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„é•œå¤´å¯¹è±¡
          const lastCompleteShot = cleanText.lastIndexOf('    }');
          if (lastCompleteShot !== -1) {
            // æˆªå–åˆ°æœ€åä¸€ä¸ªå®Œæ•´é•œå¤´ï¼Œç„¶åè¡¥å…¨JSONç»“æ„
            cleanText = cleanText.substring(0, lastCompleteShot + 5) + '\n  ]\n}';
            console.log('ğŸ”§ Repaired JSON structure');
            plan = JSON.parse(cleanText);
          } else {
            // å¦‚æœæ‰¾ä¸åˆ°å®Œæ•´çš„é•œå¤´ï¼Œä½¿ç”¨é™çº§æ–¹æ¡ˆ
            throw parseError; // æŠ›å‡ºåŸå§‹é”™è¯¯
          }
        } else {
          throw parseError;
        }
      }
    } catch (parseError) {
      console.error('âŒ Failed to parse Gemini JSON response:', parseError);
      console.error('Raw text:', text);
      
      // å°è¯•ä»æˆªæ–­çš„JSONä¸­æå–å¯ç”¨çš„é•œå¤´ä¿¡æ¯
      try {
        const shotMatches = text.match(/"id":\s*(\d+),\s*"prompt":\s*"([^"]*)",\s*"duration_s":\s*(\d+),\s*"camera":\s*"([^"]*)"/g);
        if (shotMatches && shotMatches.length > 0) {
          console.log('ğŸ”§ Attempting to extract shots from partial JSON...');
          const extractedShots = shotMatches.map((match, index) => {
            const shotMatch = match.match(/"id":\s*(\d+),\s*"prompt":\s*"([^"]*)",\s*"duration_s":\s*(\d+),\s*"camera":\s*"([^"]*)"/);
            if (shotMatch) {
              return {
                id: parseInt(shotMatch[1]),
                prompt: shotMatch[2],
                duration_s: parseInt(shotMatch[3]),
                camera: shotMatch[4]
              };
            }
            return null;
          }).filter(shot => shot !== null);
          
          if (extractedShots.length > 0) {
            plan = {
              ratio: ratio,
              total_seconds: targetSeconds,
              shots: extractedShots
            };
            console.log(`âœ… Extracted ${extractedShots.length} shots from partial JSON`);
          } else {
            throw new Error('æ— æ³•ä»æˆªæ–­çš„JSONä¸­æå–é•œå¤´ä¿¡æ¯');
          }
        } else {
          throw new Error('Geminiè¿”å›çš„JSONæ ¼å¼æœ‰è¯¯');
        }
      } catch (extractError) {
        console.error('âŒ JSON extraction also failed:', extractError);
        throw new Error('Geminiè¿”å›çš„JSONæ ¼å¼æœ‰è¯¯');
      }
    }
    
    // é‡åŒ–æ—¶é•¿åˆ°Runwayæ”¯æŒçš„å€¼ï¼ˆ5s/10sï¼‰
    if (plan.shots && Array.isArray(plan.shots)) {
      plan.shots = plan.shots.map((shot: any) => {
        const quantizedDuration = shot.duration_s <= 7 ? 5 : shot.duration_s <= 15 ? 10 : Math.min(30, shot.duration_s);
        return { ...shot, duration_s: quantizedDuration };
      });
    }

      console.log(`ğŸ“‹ Generated shot plan with Gemini:`, {
        totalShots: plan.shots?.length || 0,
        totalDuration: plan.shots?.reduce((sum: number, shot: any) => sum + shot.duration_s, 0) || 0,
        shots: plan.shots?.map((s: any) => ({ id: s.id, duration: s.duration_s, camera: s.camera })) || []
      });

      return plan;

    } catch (error) {
      lastError = error;
      const errorMessage = error instanceof Error ? error.message : String(error);

      // æ£€æŸ¥æ˜¯å¦æ˜¯503æœåŠ¡è¿‡è½½é”™è¯¯
      const is503Error = errorMessage.includes('503') || errorMessage.includes('overloaded');

      if (is503Error && attempt < maxRetries) {
        console.warn(`âš ï¸ Gemini API overloaded (attempt ${attempt}/${maxRetries}), retrying...`);
        continue; // é‡è¯•
      } else {
        // å…¶ä»–é”™è¯¯æˆ–å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
        console.error('âŒ Gemini API failed:', error);
        throw new Error(`Geminié•œå¤´è§„åˆ’å¤±è´¥: ${errorMessage}`);
      }
    }
  }

  // å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
  console.error('âŒ All Gemini API retry attempts failed');
  throw new Error(`Geminié•œå¤´è§„åˆ’å¤±è´¥ï¼ˆå·²é‡è¯•${maxRetries}æ¬¡ï¼‰: ${lastError instanceof Error ? lastError.message : String(lastError)}`);
}

/**
 * ä½¿ç”¨ Google VEO 3.1 API ç”Ÿæˆå•ä¸ªè§†é¢‘ç‰‡æ®µ
 * åŸºäºæœ€æ–°çš„ Gemini API æ–‡æ¡£: https://ai.google.dev/gemini-api/docs/video
 * ä½¿ç”¨ @google/genai SDK
 */
async function generateVideoWithVEO31(options: {
  prompt: string;
  aspectRatio?: "16:9" | "9:16";
  image?: string; // å›¾ç”Ÿè§†é¢‘ï¼šå°†å›¾ç‰‡ä½œä¸ºè§†é¢‘çš„ç¬¬ä¸€å¸§
  referenceImages?: string[]; // å‚è€ƒå›¾ç‰‡ï¼šä½œä¸ºé£æ ¼å’Œå†…å®¹çš„å‚è€ƒï¼ˆä¸æ˜¯ç¬¬ä¸€å¸§ï¼‰
  previousVideo?: string; // ç”¨äºè§†é¢‘æ‰©å±•ï¼ˆç¡®ä¿è¿ç»­æ€§ï¼‰
}): Promise<string> {
  const { prompt, aspectRatio = "16:9", image, referenceImages, previousVideo } = options;

  console.log("ğŸ¬ Generating video with VEO 3.1:", {
    promptLength: prompt.length,
    aspectRatio,
    hasImage: !!image, // å›¾ç”Ÿè§†é¢‘æ¨¡å¼
    hasReferenceImages: !!referenceImages?.length,
    hasPreviousVideo: !!previousVideo
  });

  try {
    const API_KEY = process.env.GEMINI_API_KEY;
    if (!API_KEY) {
      throw new Error("GEMINI_API_KEY is not configured");
    }

    // ä½¿ç”¨æ–°çš„ @google/genai SDK
    const { GoogleGenAI } = await import("@google/genai");
    const ai = new GoogleGenAI({ apiKey: API_KEY });

    const modelName = "veo-3.1-generate-preview"; // ä½¿ç”¨ VEO 3.1 preview æ¨¡å‹

    // æ„å»ºé…ç½®
    const config: any = {
      numberOfVideos: 1,
      aspectRatio: aspectRatio,
    };

    // æ„å»ºè¯·æ±‚å‚æ•° - æ ¹æ®ä¸åŒæ¨¡å¼é€‰æ‹©
    const requestParams: any = {
      model: modelName,
      prompt: prompt,
      config: config
    };

    // æ¨¡å¼ä¼˜å…ˆçº§ï¼š
    // 1. å›¾ç”Ÿè§†é¢‘ï¼ˆimageï¼‰- å°†å›¾ç‰‡ä½œä¸ºè§†é¢‘ç¬¬ä¸€å¸§
    // 2. è§†é¢‘æ‰©å±•ï¼ˆpreviousVideoï¼‰- ä»å‰ä¸€æ®µè§†é¢‘ç»§ç»­
    // 3. å‚è€ƒå›¾ç‰‡ï¼ˆreferenceImagesï¼‰- ä½œä¸ºé£æ ¼å’Œå†…å®¹çš„å‚è€ƒ

    if (image) {
      // âœ… å›¾ç”Ÿè§†é¢‘æ¨¡å¼ï¼šå°†ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡ä½œä¸ºè§†é¢‘çš„ç¬¬ä¸€å¸§
      console.log(`ğŸ–¼ï¸â¡ï¸ğŸ¬ Image-to-video mode: using uploaded image as starting frame`);

      const imageResponse = await fetch(image);
      if (!imageResponse.ok) {
        throw new Error(`Failed to fetch image: ${imageResponse.statusText}`);
      }

      const imageBuffer = await imageResponse.arrayBuffer();
      const base64Image = Buffer.from(imageBuffer).toString('base64');
      const mimeType = imageResponse.headers.get('content-type') || 'image/png';

      // æ·»åŠ imageå‚æ•°ï¼ˆä½œä¸ºè§†é¢‘çš„åˆå§‹å¸§ï¼‰
      requestParams.image = {
        imageBytes: base64Image,
        mimeType: mimeType
      };

      console.log(`âœ… Starting image prepared: ${mimeType}, size: ${imageBuffer.byteLength} bytes`);

    } else if (previousVideo) {
      // è§†é¢‘æ‰©å±•æ¨¡å¼ï¼šä½¿ç”¨å‰ä¸€ä¸ªè§†é¢‘çš„æœ€åä¸€å¸§ä½œä¸ºèµ·ç‚¹
      console.log(`ğŸï¸ Using video extension mode with previous video`);

      const videoResponse = await fetch(previousVideo);
      if (!videoResponse.ok) {
        throw new Error(`Failed to fetch previous video: ${videoResponse.statusText}`);
      }

      const videoBuffer = await videoResponse.arrayBuffer();
      const base64Video = Buffer.from(videoBuffer).toString('base64');
      const mimeType = videoResponse.headers.get('content-type') || 'video/mp4';

      requestParams.video = {
        videoBytes: base64Video,
        mimeType: mimeType
      };

      console.log(`âœ… Previous video prepared for extension: ${mimeType}, size: ${videoBuffer.byteLength} bytes`);

    } else if (referenceImages && referenceImages.length > 0) {
      // å‚è€ƒå›¾ç‰‡æ¨¡å¼ï¼šä½œä¸ºé£æ ¼å’Œå†…å®¹çš„å‚è€ƒï¼ˆä¸æ˜¯ç¬¬ä¸€å¸§ï¼‰
      console.log(`ğŸ–¼ï¸ Adding ${referenceImages.length} reference image(s) as style guide`);

      config.referenceImages = [];

      // VEO 3.1 æ”¯æŒæœ€å¤š3å¼ å‚è€ƒå›¾ç‰‡
      for (let i = 0; i < Math.min(referenceImages.length, 3); i++) {
        const imageUrl = referenceImages[i];
        const imageResponse = await fetch(imageUrl);

        if (!imageResponse.ok) {
          console.warn(`âš ï¸ Failed to fetch reference image ${i + 1}, skipping`);
          continue;
        }

        const imageBuffer = await imageResponse.arrayBuffer();
        const base64Image = Buffer.from(imageBuffer).toString('base64');
        const mimeType = imageResponse.headers.get('content-type') || 'image/png';

        // æ·»åŠ åˆ° referenceImages æ•°ç»„
        config.referenceImages.push({
          image: {
            imageBytes: base64Image,
            mimeType: mimeType
          },
          referenceType: "asset" // è§’è‰²/ç‰©ä½“å‚è€ƒç±»å‹
        });

        console.log(`âœ… Reference image ${i + 1} prepared: ${mimeType}, size: ${imageBuffer.byteLength} bytes`);
      }
    }

    console.log("ğŸ“¤ Sending request to VEO 3.1 API via SDK");
    console.log("ğŸš€ Final request params:", {
      model: requestParams.model,
      promptLength: requestParams.prompt.length,
      configKeys: Object.keys(requestParams.config),
      hasImage: !!requestParams.image,
      hasReferenceImages: !!requestParams.config.referenceImages,
      referenceImagesCount: requestParams.config.referenceImages?.length || 0,
      hasPreviousVideo: !!requestParams.video
    });

    // å‘èµ·è§†é¢‘ç”Ÿæˆè¯·æ±‚ï¼ˆè¿”å›ä¸€ä¸ªé•¿æ—¶é—´è¿è¡Œçš„æ“ä½œï¼‰
    let operation = await ai.models.generateVideos(requestParams);

    console.log("â³ Waiting for VEO 3.1 video generation to complete...");

    // è½®è¯¢æ“ä½œçŠ¶æ€ï¼Œç›´åˆ°è§†é¢‘ç”Ÿæˆå®Œæˆ
    while (!operation.done) {
      await new Promise((resolve) => setTimeout(resolve, 10000)); // ç­‰å¾…10ç§’
      console.log("...Still generating VEO 3.1 video...");
      operation = await ai.operations.getVideosOperation({ operation });
    }

    console.log("ğŸ“‹ VEO 3.1 video generation completed");

    // è¯¦ç»†æ£€æŸ¥å“åº”ç»“æ„
    console.log("ğŸ” Operation response structure:", {
      hasResponse: !!operation.response,
      hasError: !!operation.error,
      hasMetadata: !!operation.metadata,
      responseKeys: operation.response ? Object.keys(operation.response) : [],
      errorKeys: operation.error ? Object.keys(operation.error) : [],
      metadataKeys: operation.metadata ? Object.keys(operation.metadata) : [],
      hasGeneratedVideos: !!operation.response?.generatedVideos,
      operationName: operation.name,
      operationDone: operation.done
    });

    // å…ˆæ£€æŸ¥æ“ä½œæ˜¯å¦æœ‰é”™è¯¯
    if (operation.error) {
      console.error("âŒ Operation completed with error:", JSON.stringify(operation.error, null, 2));

      // è¾“å‡ºmetadataä»¥è·å–æ›´å¤šè¯Šæ–­ä¿¡æ¯
      if (operation.metadata) {
        console.error("ğŸ“Š Operation metadata:", JSON.stringify(operation.metadata, null, 2));
      }

      throw new Error(`VEO 3.1 æ“ä½œå¤±è´¥: ${operation.error.message || JSON.stringify(operation.error)}`);
    }

    // æ£€æŸ¥å“åº”
    if (!operation.response) {
      console.error("âŒ No response in operation. Full operation object:");
      console.error(JSON.stringify(operation, null, 2));
      throw new Error("VEO 3.1 æ“ä½œå®Œæˆä½†æ²¡æœ‰å“åº”å¯¹è±¡");
    }

    if (!operation.response.generatedVideos) {
      console.error("âŒ No generatedVideos in response. Full response object:");
      console.error(JSON.stringify(operation.response, null, 2));

      // å¦‚æœæœ‰metadataï¼Œä¹Ÿè¾“å‡º
      if (operation.metadata) {
        console.error("ğŸ“Š Operation metadata:", JSON.stringify(operation.metadata, null, 2));
      }

      throw new Error("VEO 3.1 å“åº”ä¸­æ²¡æœ‰ generatedVideos å­—æ®µ");
    }

    const videos = operation.response.generatedVideos;
    if (videos.length === 0) {
      console.error("âŒ Empty generatedVideos array");
      throw new Error("VEO 3.1 è¿”å›ç©ºçš„è§†é¢‘æ•°ç»„");
    }

    const video = videos[0];
    console.log("ğŸ“¹ Video object structure:", {
      hasVideo: !!video.video,
      hasUri: !!video.video?.uri,
      videoKeys: video.video ? Object.keys(video.video) : []
    });

    if (!video.video || !video.video.uri) {
      console.error("âŒ No video URI:", JSON.stringify(video, null, 2));
      throw new Error("VEO 3.1 è§†é¢‘å¯¹è±¡ä¸­æ²¡æœ‰ URI");
    }

    // è·å–è§†é¢‘ URIï¼ˆéœ€è¦æ·»åŠ  API keyï¼‰
    const videoUri = `${video.video.uri}&key=${API_KEY}`;

    console.log("ğŸ“¥ Downloading VEO 3.1 video from:", videoUri);

    // ä¸‹è½½è§†é¢‘
    const videoResponse = await fetch(videoUri);
    if (!videoResponse.ok) {
      throw new Error(`Failed to download VEO 3.1 video: ${videoResponse.statusText}`);
    }

    const videoBuffer = await videoResponse.arrayBuffer();
    console.log(`ğŸ’¾ Storing VEO 3.1 video, size: ${videoBuffer.byteLength} bytes`);

    // å­˜å‚¨åˆ° Supabase
    const fileName = `veo-3.1/${crypto.randomUUID()}.mp4`;
    const videoUrl = await putAndGetUrl(
      fileName,
      new Uint8Array(videoBuffer),
      'video/mp4'
    );

    console.log("âœ… VEO 3.1 video generated and stored:", videoUrl);
    return videoUrl;

  } catch (error) {
    console.error("âŒ VEO 3.1 video generation failed:", error);

    // æ£€æŸ¥æ˜¯å¦æ˜¯429é…é¢é™åˆ¶é”™è¯¯
    const errorMessage = (error as Error).message || '';
    const errorString = JSON.stringify(error);

    if (errorString.includes('"code":429') || errorMessage.includes('quota') || errorMessage.includes('RESOURCE_EXHAUSTED')) {
      throw new Error(`VEO 3.1 APIé…é¢å·²ç”¨å°½ã€‚è¯·è®¿é—® https://ai.dev/usage æŸ¥çœ‹ä½¿ç”¨æƒ…å†µï¼Œæˆ–å‡çº§åˆ°ä»˜è´¹å¥—é¤ã€‚å»ºè®®ç­‰å¾…24å°æ—¶åé‡è¯•ã€‚`);
    }

    throw new Error(`VEO 3.1è§†é¢‘ç”Ÿæˆå¤±è´¥: ${errorMessage}`);
  }
}

/**
 * ä»ç”¨æˆ·æç¤ºè¯ä¸­æå–è§’è‰²æè¿°
 */
function extractCharacterDescription(prompt: string): string | null {
  // å¯»æ‰¾è§’è‰²ç›¸å…³çš„æè¿°
  const characterKeywords = ['ä¸»è§’', 'è§’è‰²', 'äººç‰©', 'å¥³æ€§', 'ç”·æ€§', 'å¹´è½»', 'è€äºº', 'å­©å­', 'character', 'person', 'woman', 'man', 'girl', 'boy'];

  // æ£€æŸ¥æ˜¯å¦åŒ…å«è§’è‰²å…³é”®è¯
  const hasCharacter = characterKeywords.some(keyword =>
    prompt.toLowerCase().includes(keyword.toLowerCase())
  );

  if (!hasCharacter) {
    return null;
  }

  // æå–è§’è‰²ç›¸å…³çš„æè¿°æ®µè½
  // å¯»æ‰¾åŒ…å«"ä¸»è§’"ã€"äººç‰©"ç­‰å…³é”®è¯çš„å¥å­
  const sentences = prompt.split(/[ã€‚\nï¼Œ,;ï¼›]/);
  const characterSentences = sentences.filter(s =>
    characterKeywords.some(k => s.includes(k))
  );

  if (characterSentences.length === 0) {
    return null;
  }

  // ç»„åˆè§’è‰²æè¿°
  let characterDesc = characterSentences.join(', ').trim();

  // æ·»åŠ "æ­£é¢å…¨èº«ç…§"æç¤ºï¼Œç¡®ä¿ç”Ÿæˆå®Œæ•´çš„è§’è‰²å‚è€ƒå›¾
  characterDesc = `Full body portrait, front view, ${characterDesc}, high quality, detailed, professional photography, neutral background`;

  return characterDesc;
}

/**
 * ä½¿ç”¨Gemini VEO 3.1ç”Ÿæˆé•¿è§†é¢‘
 */
export interface GeminiLongVideoOptions {
  prompt: string;
  attachedImages: string[]; // é™„åŠ å›¾ç‰‡URLæ•°ç»„
  jobId: string;
  shotPlan?: any; // å¯é€‰çš„é•œå¤´è§„åˆ’
  model?: string; // VEOæ¨¡å‹ç‰ˆæœ¬ï¼Œå¦‚ "veo-3.1"
  onProgress?: (progress: { percentage: number; step: string; message: string }) => Promise<void>;
}

export async function generateLongVideoGemini(options: GeminiLongVideoOptions) {
  const { prompt, attachedImages, jobId, shotPlan: providedShotPlan, model = "veo-3.1", onProgress } = options;

  console.log("ğŸ¬ Starting Google VEO 3.1 long video generation:", {
    jobId,
    prompt: prompt.substring(0, 100) + "...",
    imagesCount: attachedImages.length,
    model,
    hasShotPlan: !!providedShotPlan
  });

  try {
    let shotPlan;

    if (providedShotPlan) {
      // ä½¿ç”¨æä¾›çš„é•œå¤´è§„åˆ’
      shotPlan = providedShotPlan;
      console.log("ğŸ“‹ Using provided shot plan:", {
        totalShots: shotPlan.shots?.length || 0,
        totalDuration: shotPlan.total_seconds || 0
      });

      await onProgress?.({
        percentage: 5,
        step: "ä½¿ç”¨ç¡®è®¤è§„åˆ’",
        message: "æ­£åœ¨ä½¿ç”¨æ‚¨ç¡®è®¤çš„é•œå¤´è§„åˆ’..."
      });
    } else {
      // æ­¥éª¤1: ä½¿ç”¨Geminiç”Ÿæˆé•œå¤´è§„åˆ’
      await onProgress?.({
        percentage: 5,
        step: "æ™ºèƒ½åˆ†æ",
        message: "æ­£åœ¨ä½¿ç”¨AIåˆ†ææç¤ºè¯å¹¶è§„åˆ’é•œå¤´åºåˆ—..."
      });

      // VEO 3.1 æ¯æ®µè§†é¢‘å›ºå®š8ç§’ï¼Œè®¡ç®—éœ€è¦çš„é•œå¤´æ•°
      const targetDuration = 60; // ç›®æ ‡60ç§’
      const segmentDuration = 8; // VEO 3.1 å›ºå®š8ç§’
      const targetShots = Math.ceil(targetDuration / segmentDuration);

      shotPlan = await generateShotPlanWithGemini(prompt, targetDuration, "16:9");

      console.log("ğŸ“‹ Generated shot plan:", {
        totalShots: shotPlan.shots.length,
        totalDuration: shotPlan.total_seconds,
        shots: shotPlan.shots.map(s => ({ id: s.id, duration: s.duration_s }))
      });
    }

    // æ­¥éª¤2: å‡†å¤‡ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡ï¼ˆç”¨äºå›¾ç”Ÿè§†é¢‘ï¼‰
    let userUploadedImages: string[] = [];
    let aiGeneratedReferenceImages: string[] = [];

    if (attachedImages && attachedImages.length > 0) {
      // âœ… ç”¨æˆ·ä¸Šä¼ äº†å›¾ç‰‡ï¼šç”¨äºå›¾ç”Ÿè§†é¢‘ï¼ˆimage-to-videoï¼‰
      userUploadedImages = attachedImages.slice(0, 1); // åªä½¿ç”¨ç¬¬ä¸€å¼ ä½œä¸ºè§†é¢‘èµ·ç‚¹
      console.log(`ğŸ–¼ï¸ User uploaded ${attachedImages.length} image(s), will use first image for image-to-video`);
    } else {
      // âŒ ç”¨æˆ·æ²¡æœ‰ä¸Šä¼ å›¾ç‰‡ï¼šçº¯æ–‡ç”Ÿè§†é¢‘ï¼ˆtext-to-videoï¼‰
      console.log(`ğŸ“ No uploaded images, will use text-to-video mode`);

      // å¯é€‰ï¼šä»æç¤ºè¯ä¸­æå–è§’è‰²æè¿°å¹¶ç”Ÿæˆå‚è€ƒå›¾ï¼ˆç”¨äºä¿æŒè¿ç»­æ€§ï¼‰
      await onProgress?.({
        percentage: 8,
        step: "ç”Ÿæˆè§’è‰²å‚è€ƒå›¾",
        message: "æ­£åœ¨ç”Ÿæˆè§’è‰²å‚è€ƒå›¾ä»¥ç¡®ä¿è§†é¢‘è¿è´¯æ€§..."
      });

      const characterPrompt = extractCharacterDescription(prompt);
      if (characterPrompt) {
        console.log("ğŸ¨ Generating character reference image for consistency:", characterPrompt);

        try {
          const charImageResult = await generateImageGemini(characterPrompt);
          aiGeneratedReferenceImages = [charImageResult.url];
          console.log("âœ… AI-generated reference image created:", charImageResult.url);
        } catch (error) {
          console.warn("âš ï¸ Failed to generate character reference, will proceed without:", error);
        }
      }
    }

    // æ­¥éª¤3: å‡†å¤‡è§†é¢‘ç”Ÿæˆ
    await onProgress?.({
      percentage: 10,
      step: "å‡†å¤‡ç”Ÿæˆ",
      message: "æ­£åœ¨å‡†å¤‡è§†é¢‘ç”Ÿæˆå‚æ•°..."
    });

    // æ­¥éª¤4: æŒ‰é•œå¤´é¡ºåºç”Ÿæˆè§†é¢‘ç‰‡æ®µï¼ˆä½¿ç”¨è§’è‰²å‚è€ƒå›¾ç¡®ä¿ä¸€è‡´æ€§ï¼‰
    const generatedSegments: string[] = [];
    const totalShots = shotPlan.shots.length;

    for (let i = 0; i < totalShots; i++) {
      const shot = shotPlan.shots[i];
      const progressBase = 15 + (i * 70) / totalShots;

      await onProgress?.({
        percentage: progressBase,
        step: `ç”Ÿæˆé•œå¤´ ${i + 1}/${totalShots}`,
        message: `æ­£åœ¨ç”Ÿæˆé•œå¤´${i + 1}ï¼š8ç§’è§†é¢‘`
      });

      // é‡è¯•é€»è¾‘ï¼šæ¯ä¸ªé•œå¤´æœ€å¤šé‡è¯•3æ¬¡
      let retryCount = 0;
      const maxRetries = 3;
      let segmentUrl: string | null = null;

      while (retryCount < maxRetries && !segmentUrl) {
        try {
          const videoPrompt = shot.prompt;

          if (retryCount > 0) {
            console.log(`ğŸ”„ Retrying shot ${i + 1} (attempt ${retryCount + 1}/${maxRetries})...`);
            await onProgress?.({
              percentage: progressBase,
              step: `é‡è¯•é•œå¤´ ${i + 1}`,
              message: `æ­£åœ¨é‡è¯•é•œå¤´${i + 1}ï¼ˆç¬¬${retryCount + 1}æ¬¡å°è¯•ï¼‰...`
            });
            // ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•ï¼Œé¿å…è§¦å‘é€Ÿç‡é™åˆ¶
            await new Promise(resolve => setTimeout(resolve, 5000 * retryCount));
          }

          console.log(`ğŸ“¹ Generating VEO 3.1 segment ${i + 1}/${totalShots}:`, {
            prompt: videoPrompt.substring(0, 100) + "...",
            shotNumber: i + 1,
            hasUserUploadedImages: userUploadedImages.length > 0,
            hasAIGeneratedReference: aiGeneratedReferenceImages.length > 0,
            attempt: retryCount + 1
          });

          // ğŸ”‘ å…³é”®ç­–ç•¥ï¼š
          // 1. ç”¨æˆ·ä¸Šä¼ äº†å›¾ç‰‡ï¼š
          //    - ç¬¬1ä¸ªé•œå¤´ï¼šå›¾ç”Ÿè§†é¢‘ï¼ˆimage-to-videoï¼‰- ä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡ä½œä¸ºç¬¬ä¸€å¸§
          //    - ç¬¬2+é•œå¤´ï¼šè§†é¢‘æ‰©å±•ï¼ˆvideo extensionï¼‰- ä»å‰ä¸€æ®µè§†é¢‘ç»§ç»­
          // 2. ç”¨æˆ·æ²¡ä¸Šä¼ å›¾ç‰‡ï¼š
          //    - ç¬¬1ä¸ªé•œå¤´ï¼šæ–‡ç”Ÿè§†é¢‘ï¼ˆtext-to-videoï¼‰æˆ–ä½¿ç”¨AIç”Ÿæˆçš„å‚è€ƒå›¾
          //    - ç¬¬2+é•œå¤´ï¼šè§†é¢‘æ‰©å±•ï¼ˆvideo extensionï¼‰- ä»å‰ä¸€æ®µè§†é¢‘ç»§ç»­
          //
          // æ³¨æ„ï¼š@google/genai SDK v1.13.0 ä¸æ”¯æŒ video å‚æ•°
          // é™çº§æ–¹æ¡ˆï¼šShot 2-4 ä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡ä½œä¸ºå‚è€ƒå›¾ï¼ˆè€Œä¸æ˜¯è§†é¢‘æ‰©å±•ï¼‰
          segmentUrl = await generateVideoWithVEO31({
            prompt: videoPrompt,
            aspectRatio: shotPlan.ratio === "768:1280" ? "9:16" : "16:9",
            // âœ… ç¬¬1ä¸ªé•œå¤´ + ç”¨æˆ·ä¸Šä¼ äº†å›¾ç‰‡ = å›¾ç”Ÿè§†é¢‘ï¼ˆä½¿ç”¨ç”¨æˆ·å›¾ç‰‡ä½œä¸ºç¬¬ä¸€å¸§ï¼‰
            image: (i === 0 && userUploadedImages.length > 0)
              ? userUploadedImages[0]
              : undefined,
            // âŒ SDK ä¸æ”¯æŒ previousVideoï¼Œæš‚æ—¶ç¦ç”¨
            // previousVideo: (i > 0 && generatedSegments.length > 0)
            //   ? generatedSegments[generatedSegments.length - 1]
            //   : undefined,
            // âœ… é™çº§æ–¹æ¡ˆï¼šShot 2-4 ä¹Ÿä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡ä½œä¸ºå‚è€ƒ
            referenceImages: (i > 0 && userUploadedImages.length > 0)
              ? userUploadedImages
              : (userUploadedImages.length === 0 && aiGeneratedReferenceImages.length > 0)
              ? aiGeneratedReferenceImages
              : undefined
          });

          console.log(`âœ… Generated VEO 3.1 shot ${i + 1}/${totalShots}:`, segmentUrl);

          await onProgress?.({
            percentage: progressBase + (70 / totalShots),
            step: `é•œå¤´ ${i + 1} å®Œæˆ`,
            message: `é•œå¤´${i + 1}ç”Ÿæˆå®Œæˆ`
          });

        } catch (error) {
          retryCount++;
          console.error(`âŒ Failed to generate shot ${i + 1} (attempt ${retryCount}/${maxRetries}):`, error);

          // å¦‚æœå·²ç»è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒæŠ›å‡ºé”™è¯¯
          if (retryCount >= maxRetries) {
            throw new Error(`é•œå¤´${i + 1}ç”Ÿæˆå¤±è´¥ï¼ˆå·²é‡è¯•${maxRetries}æ¬¡ï¼‰: ${(error as Error).message}`);
          }
        }
      }

      if (segmentUrl) {
        generatedSegments.push(segmentUrl);
      }
    }

    // æ­¥éª¤4: æ‹¼æ¥æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
    await onProgress?.({
      percentage: 90,
      step: "æ‹¼æ¥è§†é¢‘",
      message: "æ­£åœ¨æ‹¼æ¥æ‰€æœ‰è§†é¢‘ç‰‡æ®µ..."
    });

    console.log(`ğŸï¸ Concatenating ${generatedSegments.length} VEO 3.1 video segments`);

    // å¯¼å…¥éœ€è¦çš„å·¥å…·
    const { downloadFile } = await import("@/lib/video/ffmpeg-utils");
    const fs = await import('fs/promises');
    const path = await import('path');
    const os = await import('os');

    // åˆ›å»ºä¸´æ—¶ç›®å½•
    const tempDir = await fs.mkdtemp(path.join(os.tmpdir(), 'veo31-concat-'));
    const localSegments: string[] = [];

    let finalUrl: string;

    try {
      // ä¸‹è½½æ‰€æœ‰è§†é¢‘ç‰‡æ®µåˆ°æœ¬åœ°
      for (let i = 0; i < generatedSegments.length; i++) {
        const segmentUrl = generatedSegments[i];
        const localPath = path.join(tempDir, `segment-${i + 1}.mp4`);
        await downloadFile(segmentUrl, localPath);
        localSegments.push(localPath);
      }

      // âš ï¸ Vercel serverless ç¯å¢ƒä¸æ”¯æŒ FFmpegï¼Œæš‚æ—¶è¿”å›æ‰€æœ‰ç‰‡æ®µ URL
      // æœªæ¥å¯ä»¥ä½¿ç”¨æ”¯æŒ FFmpeg çš„äº‘æœåŠ¡è¿›è¡Œè§†é¢‘æ‹¼æ¥
      if (localSegments.length > 1) {
        console.log(`ğŸ“¦ Returning ${localSegments.length} video segments (FFmpeg not available in serverless)`);

        // ä¸Šä¼ æ‰€æœ‰ç‰‡æ®µå¹¶è¿”å› URL æ•°ç»„
        const segmentUrls: string[] = [];
        for (let i = 0; i < localSegments.length; i++) {
          const segmentBuffer = await fs.readFile(localSegments[i]);
          const segmentUrl = await putAndGetUrl(
            `veo-3.1/${jobId}/segment-${i + 1}.mp4`,
            new Uint8Array(segmentBuffer),
            'video/mp4'
          );
          segmentUrls.push(segmentUrl);
        }

        // ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰‡æ®µä½œä¸ºä¸»è§†é¢‘ï¼ˆå‘åå…¼å®¹ï¼‰
        finalUrl = segmentUrls[0];

        console.log(`âœ… Uploaded ${segmentUrls.length} segments:`, segmentUrls);
      } else {
        // åªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥ä¸Šä¼ 
        const finalVideoBuffer = await fs.readFile(localSegments[0]);
        finalUrl = await putAndGetUrl(
          `veo-3.1/${jobId}/final.mp4`,
          new Uint8Array(finalVideoBuffer),
          'video/mp4'
        );
      }

      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      await fs.rm(tempDir, { recursive: true, force: true }).catch(() => {});

    } catch (error) {
      // ç¡®ä¿æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      await fs.rm(tempDir, { recursive: true, force: true }).catch(() => {});
      throw error;
    }

    await onProgress?.({
      percentage: 100,
      step: "å®Œæˆ",
      message: "é•¿è§†é¢‘ç”Ÿæˆå®Œæˆï¼"
    });

    console.log("âœ… Google VEO 3.1 long video generation completed:", finalUrl);

    return {
      url: finalUrl,
      segments: generatedSegments,
      duration: generatedSegments.length * 8 // VEO 3.1 æ¯æ®µ8ç§’
    };

  } catch (error) {
    console.error("âŒ Google VEO 3.1 long video generation failed:", error);
    throw new Error(`é•¿è§†é¢‘ç”Ÿæˆå¤±è´¥: ${(error as Error).message}`);
  }
}