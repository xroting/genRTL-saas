import { putAndGetUrl } from "@/lib/storage";

// Runway API é…ç½®
const RUNWAY_API_KEY = process.env.RUNWAY_API_KEY!;
const RUNWAY_API_BASE_URL = "https://api.dev.runwayml.com/v1";

// Runway API æ”¯æŒçš„è§†é¢‘æ¯”ä¾‹ (video-to-video)
const VALID_RATIOS_VIDEO_TO_VIDEO = ["1280:720", "720:1280", "1104:832", "960:960", "832:1104", "1584:672", "848:480", "640:480"];

// Runway API æ”¯æŒçš„å›¾ç‰‡è½¬è§†é¢‘æ¯”ä¾‹ (image-to-video)
const VALID_RATIOS_IMAGE_TO_VIDEO = ["768:1280", "1280:768"];

// éªŒè¯å¹¶ä¿®æ­£ratioå‚æ•° (video-to-video)
function validateAndFixRatio(ratio: string): string {
  if (!VALID_RATIOS_VIDEO_TO_VIDEO.includes(ratio)) {
    console.warn(`âš ï¸ Invalid video-to-video ratio ${ratio}, using default 1280:720`);
    return "1280:720";
  }
  return ratio;
}

// éªŒè¯å¹¶ä¿®æ­£ratioå‚æ•° (image-to-video)
function validateAndFixRatioImageToVideo(ratio: string): string {
  if (!VALID_RATIOS_IMAGE_TO_VIDEO.includes(ratio)) {
    console.warn(`âš ï¸ Invalid image-to-video ratio ${ratio}, using default 1280:768 (landscape)`);
    return "1280:768"; // é»˜è®¤ä½¿ç”¨æ¨ªå±
  }
  return ratio;
}

// æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©æ­£ç¡®çš„æ¨¡å‹
// æ ¹æ® Runway API æ–‡æ¡£: https://docs.dev.runwayml.com/guides/models/
function selectModelForTask(taskType: 'image_to_video' | 'video_to_video' | 'text_to_video', providedModel?: string): string {
  // ä¸åŒç«¯ç‚¹æ”¯æŒçš„æ¨¡å‹
  const videoToVideoModels = ['gen4_aleph']; // video-to-video åªæ”¯æŒ gen4_aleph
  const imageToVideoModels = ['gen3a_turbo', 'gen3a', 'gen4_turbo', 'gen4_aleph'];
  const otherModels = ['act_two', 'veo3', 'veo3.1', 'veo3.1_fast'];

  switch (taskType) {
    case 'video_to_video':
      // video-to-video ç«¯ç‚¹ä»…æ”¯æŒ gen4_aleph æ¨¡å‹
      if (providedModel && videoToVideoModels.includes(providedModel)) {
        return providedModel;
      }
      return 'gen4_aleph'; // å¿…é¡»ä½¿ç”¨ gen4_aleph

    case 'image_to_video':
    case 'text_to_video':
    default:
      // image-to-video æ”¯æŒæ›´å¤šæ¨¡å‹
      const allImageModels = [...imageToVideoModels, ...otherModels];
      if (providedModel && allImageModels.includes(providedModel)) {
        return providedModel;
      }
      return 'gen3a_turbo'; // é»˜è®¤ä½¿ç”¨ gen3a_turbo
  }
}

// è·å– video-to-video çš„æ¨¡å‹å›é€€åˆ—è¡¨ï¼ˆåªæœ‰ä¸€ä¸ªå¯ç”¨ï¼‰
function getVideoToVideoModelFallbacks(): string[] {
  return ['gen4_aleph']; // video-to-video ä»…æ”¯æŒæ­¤æ¨¡å‹
}

// å¸¦é‡è¯•çš„fetchå‡½æ•°
async function fetchWithRetry(url: string, options: RequestInit, retries: number = 3): Promise<Response> {
  for (let i = 0; i < retries; i++) {
    try {
      console.log(`ğŸ”„ Fetch attempt ${i + 1}/${retries} to ${url}`);
      
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 60000); // 60ç§’è¶…æ—¶
      
      const response = await fetch(url, {
        ...options,
        signal: controller.signal
      });
      
      clearTimeout(timeoutId);
      return response;
      
    } catch (error) {
      console.warn(`âš ï¸ Fetch attempt ${i + 1} failed:`, (error as Error).message);
      
      if (i === retries - 1) {
        throw error; // æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯
      }
      
      // ç­‰å¾…åé‡è¯•
      const delay = Math.min(1000 * Math.pow(2, i), 10000); // æŒ‡æ•°é€€é¿ï¼Œæœ€å¤§10ç§’
      console.log(`â³ Waiting ${delay}ms before retry...`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  
  throw new Error("All retry attempts failed");
}

export interface RunwayVideoOptions {
  prompt: string;
  referenceImageUrl?: string;
  referenceVideoUrl?: string; // å‚è€ƒè§†é¢‘URLï¼ˆç”¨äºç‰¹æ•ˆå¤„ç†ï¼‰
  duration?: number; // è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
  ratio?: string;    // æ¯”ä¾‹ï¼Œå¦‚ "1280:720"
  model?: string;    // æ¨¡å‹åç§°
  fixedImagePath?: string; // å›ºå®šå›¾ç‰‡è·¯å¾„ï¼ˆæ¥è‡ªpublicç›®å½•ï¼‰
  imageToVideo?: boolean; // æ˜¯å¦ä¸ºå›¾ç‰‡è½¬è§†é¢‘æ¨¡å¼
}

export interface RunwayLongVideoOptions {
  prompt: string;
  attachedImages: string[]; // é™„åŠ å›¾ç‰‡URLæ•°ç»„
  jobId: string;
  shotPlan?: any; // å¯é€‰çš„é•œå¤´è§„åˆ’ï¼Œå¦‚æœæä¾›åˆ™è·³è¿‡è§„åˆ’æ­¥éª¤
  model?: string; // å¯é€‰çš„æ¨¡å‹åç§°ï¼ˆå¦‚ "veo3.1"ï¼‰
  onProgress?: (progress: { percentage: number; step: string; message: string }) => Promise<void>;
}

export interface VideoSegment {
  id: string;
  prompt: string;
  imageUrl?: string;
  videoUrl?: string;
  duration: number;
  order: number;
}

export async function generateVideoRunway(options: RunwayVideoOptions) {
  const {
    prompt,
    referenceImageUrl,
    referenceVideoUrl,
    duration = 5,
    ratio: rawRatio = "1280:720", // é»˜è®¤å€¼ï¼Œä¼šæ ¹æ®æ¨¡å¼è°ƒæ•´
    model, // ä¸è®¾ç½®é»˜è®¤å€¼ï¼Œç”±ä»»åŠ¡ç±»å‹å†³å®š
    fixedImagePath,
    imageToVideo
  } = options;

  console.log("ğŸ¬ Starting Runway video generation:", { prompt, referenceImageUrl, referenceVideoUrl, duration, ratio: rawRatio, model, fixedImagePath, imageToVideo });

  try {
    // å¤„ç†å›ºå®šå›¾ç‰‡è·¯å¾„ï¼Œè½¬æ¢ä¸ºå®Œæ•´URL
    let fixedImageUrl: string | undefined;
    if (fixedImagePath) {
      // å°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºå®Œæ•´URLï¼ˆå‡è®¾éƒ¨ç½²åœ¨åŸŸåä¸‹ï¼‰
      fixedImageUrl = `${process.env.NEXTAUTH_URL || 'http://localhost:3000'}${fixedImagePath}`;
      console.log("ğŸ–¼ï¸ Using fixed image:", fixedImageUrl);
    }

    // å¦‚æœæ˜¯å›¾ç‰‡è½¬è§†é¢‘æ¨¡å¼ï¼Œä½¿ç”¨ä¸“é—¨çš„å¤„ç†é€»è¾‘
    if (imageToVideo && referenceImageUrl) {
      console.log("ğŸ“¸ Using image-to-video mode");
      // å¯¹äºimage-to-videoï¼Œä½¿ç”¨ä¸“é—¨çš„ratioéªŒè¯ï¼ˆåœ¨processImageToVideoå†…éƒ¨ï¼‰
      return await processImageToVideo({
        imageUrl: referenceImageUrl,
        prompt,
        duration,
        ratio: rawRatio, // ç›´æ¥ä¼ é€’åŸå§‹ratioï¼Œåœ¨processImageToVideoå†…éƒ¨éªŒè¯
        model
      });
    }

    // å¯¹äºvideo-to-videoï¼ŒéªŒè¯å¹¶ä¿®æ­£ratioå‚æ•°
    const ratio = validateAndFixRatio(rawRatio);

    // å¦‚æœæœ‰å›ºå®šå›¾ç‰‡å’Œç”¨æˆ·è§†é¢‘ï¼Œä½¿ç”¨ç‰¹æ®Šå¤„ç†é€»è¾‘
    if (fixedImageUrl && referenceVideoUrl) {
      console.log("ğŸ­ Using fixed image + user video mode");
      return await processVideoWithFixedImage({
        videoUrl: referenceVideoUrl,
        imageUrl: fixedImageUrl,
        prompt,
        duration,
        ratio,
        model
      });
    }

    // å¦‚æœåŒæ—¶æœ‰è§†é¢‘å’Œå›¾ç‰‡ï¼Œè¿™æ˜¯è§’è‰²ä»»åŠ¡
    if (referenceVideoUrl && referenceImageUrl) {
      console.log("ğŸ­ Starting face swap process");

      // é¦–å…ˆå°è¯•ä½¿ç”¨ Act-Two APIï¼ˆå¦‚æœå¯ç”¨ï¼‰
      try {
        return await generateFaceSwapWithActTwo({
          drivingVideoUrl: referenceVideoUrl!,
          characterImageUrl: referenceImageUrl!,
          prompt,
          duration,
          ratio,
          model: model || 'act_two'
        });
      } catch (error) {
        console.warn("âš ï¸ Act-Two not available, falling back to alternative method:", (error as Error).message);

        // å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ”¹è¿›çš„ video-to-video æ–¹æ³•
        return await generateFaceSwapFallback({
          drivingVideoUrl: referenceVideoUrl!,
          characterImageUrl: referenceImageUrl!,
          prompt,
          duration,
          ratio,
          model: selectModelForTask('image_to_video', model)
        });
      }
    }
    // å¦‚æœåªæœ‰è§†é¢‘è¾“å…¥ï¼Œä½¿ç”¨video-to-videoç«¯ç‚¹å¤„ç†è§†é¢‘ç‰¹æ•ˆ
    else if (referenceVideoUrl) {
      console.log("ğŸ“¹ Using video-to-video mode for video effects");
      const taskData = await processVideoToVideo(referenceVideoUrl!, prompt, { model: selectModelForTask('video_to_video', model), duration, ratio });
      return await finishVideoToVideoTask(taskData);
    }
    
    // æ ¹æ®æ–‡æ¡£ï¼Œæ²¡æœ‰å•ç‹¬çš„text-to-videoç«¯ç‚¹ï¼Œä½¿ç”¨image_to_videoç«¯ç‚¹
    const endpoint = '/image_to_video';
    const requestBody: any = {
      promptText: prompt,
      model: selectModelForTask('image_to_video', model), // é€‰æ‹©æ­£ç¡®çš„image-to-videoæ¨¡å‹
      ratio: validateAndFixRatio(ratio || "1280:720") // å¿…é¡»ä¼ é€’ratioå‚æ•°
    };
    
    // å¦‚æœæœ‰å‚è€ƒå›¾ç‰‡ï¼Œæ·»åŠ promptImageå‚æ•°
    if (referenceImageUrl) {
      requestBody.promptImage = referenceImageUrl;
    } else {
      // å¦‚æœæ²¡æœ‰å‚è€ƒå›¾ç‰‡ï¼Œä½¿ç”¨text-to-videoæ¨¡å¼
      // æ ¹æ®Runway APIæ–‡æ¡£ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸åŒçš„ç«¯ç‚¹
      return await generateTextToVideo(prompt, { duration, ratio, model: selectModelForTask('text_to_video', model) });
    }
    
    // æ·»åŠ durationå‚æ•°
    if (duration && (duration === 5 || duration === 10)) {
      requestBody.duration = duration;
    }

    console.log("ğŸ“¤ Sending request to Runway API:", { endpoint, requestBody });
    
    // åˆ›å»ºè§†é¢‘ç”Ÿæˆä»»åŠ¡
    const response = await fetch(`${RUNWAY_API_BASE_URL}${endpoint}`, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${RUNWAY_API_KEY}`,
        "Content-Type": "application/json",
        "X-Runway-Version": "2024-11-06"
      },
      body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("âŒ Runway API error:", response.status, errorText);

      // è§£æé”™è¯¯ä¿¡æ¯å¹¶æä¾›æ›´å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
      try {
        const errorData = JSON.parse(errorText);
        if (errorData.error && errorData.error.includes('ratio')) {
          throw new Error("è§†é¢‘æ¯”ä¾‹å‚æ•°é”™è¯¯ï¼Œè¯·æ£€æŸ¥è®¾ç½®åé‡è¯•");
        }
      } catch (parseError) {
        // å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é€šç”¨é”™è¯¯ä¿¡æ¯
      }

      throw new Error("è§†é¢‘ç”ŸæˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•");
    }

    const taskData = await response.json();
    console.log("ğŸ“‹ Task created:", taskData.id);

    // è½®è¯¢ç­‰å¾…ä»»åŠ¡å®Œæˆ
    const videoUrl = await waitForVideoGeneration(taskData.id);
    
    // ä¸‹è½½å¹¶å­˜å‚¨è§†é¢‘åˆ°Supabase Storage
    console.log("ğŸ’¾ Downloading and storing video...");
    const videoResponse = await fetch(videoUrl);
    if (!videoResponse.ok) {
      console.error("âŒ Failed to download video:", videoResponse.status);
      throw new Error("è§†é¢‘ä¸‹è½½å¤±è´¥ï¼Œè¯·é‡æ–°å°è¯•");
    }

    const videoBuffer = Buffer.from(await videoResponse.arrayBuffer());
    const storageUrl = await putAndGetUrl(
      `runway/${crypto.randomUUID()}.mp4`, 
      videoBuffer, 
      "video/mp4"
    );

    console.log("âœ… Video stored successfully:", storageUrl);
    return { url: storageUrl };

  } catch (error) {
    console.error("âŒ Runway video generation failed:", error);
    // å¦‚æœé”™è¯¯å·²ç»æ˜¯å‹å¥½çš„ç”¨æˆ·æ¶ˆæ¯ï¼Œç›´æ¥æŠ›å‡ºï¼›å¦åˆ™ä½¿ç”¨é€šç”¨æ¶ˆæ¯
    if ((error as Error).message.includes("è§†é¢‘ç”ŸæˆæœåŠ¡") || (error as Error).message.includes("è§†é¢‘ä¸‹è½½å¤±è´¥")) {
      throw error;
    }
    throw new Error("è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•");
  }
}

async function waitForVideoGeneration(taskId: string, maxAttempts: number = 60): Promise<string> {
  console.log(`â³ Waiting for task ${taskId} to complete...`);
  
  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      const response = await fetch(`${RUNWAY_API_BASE_URL}/tasks/${taskId}`, {
        headers: {
          "Authorization": `Bearer ${RUNWAY_API_KEY}`,
          "X-Runway-Version": "2024-11-06"
        }
      });

      if (!response.ok) {
        console.error("âŒ Task status check failed:", response.status);
        throw new Error("è§†é¢‘ç”ŸæˆçŠ¶æ€æŸ¥è¯¢å¤±è´¥");
      }

      const taskData = await response.json();
      console.log(`ğŸ“Š Task ${taskId} status: ${taskData.status} (attempt ${attempt}/${maxAttempts})`);

      if (taskData.status === 'SUCCEEDED') {
        if (taskData.output && taskData.output.length > 0) {
          const videoUrl = taskData.output[0];
          console.log("ğŸ‰ Video generation completed:", videoUrl);
          return videoUrl;
        } else {
          console.error("âŒ Task succeeded but no output URL found");
          throw new Error("è§†é¢‘ç”Ÿæˆå®Œæˆä½†ç»“æœè·å–å¤±è´¥");
        }
      } else if (taskData.status === 'FAILED') {
        const failureReason = taskData.failure_reason || taskData.failure || taskData.error || "æœªçŸ¥é”™è¯¯";
        const failureCode = taskData.failureCode || taskData.failure_code || taskData.errorCode;
        console.error("âŒ Task failed:", failureReason);
        console.error("âŒ Failure code:", failureCode);
        console.error("âŒ Full task data:", JSON.stringify(taskData, null, 2));

        // æ ¹æ®å¤±è´¥åŸå› æä¾›æ›´å…·ä½“çš„é”™è¯¯ä¿¡æ¯
        if (failureCode === "NO_FACE_FOUND" || failureReason.includes("No face found")) {
          throw new Error("PERMANENT_FAILURE: æœªåœ¨å›¾ç‰‡æˆ–è§†é¢‘ä¸­æ£€æµ‹åˆ°äººè„¸ï¼Œè¯·ä¸Šä¼ åŒ…å«æ¸…æ™°äººè„¸çš„ç´ æ");
        } else if (failureReason.includes("content policy") || failureReason.includes("policy")) {
          throw new Error("PERMANENT_FAILURE: è§†é¢‘å†…å®¹ä¸ç¬¦åˆå¹³å°æ”¿ç­–ï¼Œè¯·ä¿®æ”¹æç¤ºè¯åé‡è¯•");
        } else if (failureReason.includes("timeout") || failureReason.includes("time")) {
          throw new Error("è§†é¢‘ç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•");
        } else if (failureReason.includes("image") || failureReason.includes("frame")) {
          throw new Error("PERMANENT_FAILURE: å…³é”®å¸§å›¾ç‰‡å¤„ç†å¤±è´¥ï¼Œè¯·é‡æ–°ä¸Šä¼ å›¾ç‰‡");
        } else if (failureCode === "INTERNAL.BAD_OUTPUT.CODE01") {
          // ç«‹å³åœæ­¢pollingå¹¶æŠ›å‡ºç‰¹å®šé”™è¯¯ä»¥è§¦å‘é‡è¯•
          throw new Error("RUNWAY_BAD_OUTPUT: è§†é¢‘ç”Ÿæˆå†…å®¹ä¸ç¬¦åˆè¦æ±‚ï¼Œå°†å°è¯•ç®€åŒ–æç¤ºè¯é‡æ–°ç”Ÿæˆ");
        } else {
          throw new Error(`PERMANENT_FAILURE: è§†é¢‘ç”Ÿæˆå¤±è´¥: ${failureReason}`);
        }
      } else if (taskData.status === 'CANCELLED') {
        throw new Error("PERMANENT_FAILURE: è§†é¢‘ç”Ÿæˆå·²å–æ¶ˆ");
      }

      // ç­‰å¾…5ç§’åé‡è¯•
      await new Promise(resolve => setTimeout(resolve, 5000));

    } catch (error) {
      const errorMessage = (error as Error).message || '';

      // æ°¸ä¹…æ€§å¤±è´¥ï¼šç«‹å³åœæ­¢è½®è¯¢å¹¶æŠ›å‡ºé”™è¯¯
      if (errorMessage.includes('PERMANENT_FAILURE') ||
          errorMessage.includes('RUNWAY_BAD_OUTPUT')) {
        console.error(`âŒ Permanent failure detected, stopping polling:`, errorMessage);
        throw error;
      }

      // è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•°ï¼šåœæ­¢è½®è¯¢
      if (attempt === maxAttempts) {
        console.error(`âŒ Task polling failed after ${maxAttempts} attempts:`, errorMessage);
        throw new Error("è§†é¢‘ç”Ÿæˆè¶…æ—¶ï¼Œè¯·é‡æ–°å°è¯•");
      }

      // ä¸´æ—¶æ€§é”™è¯¯ï¼šç»§ç»­é‡è¯•
      console.warn(`âš ï¸ Polling attempt ${attempt} failed, retrying...`);
      await new Promise(resolve => setTimeout(resolve, 5000));
    }
  }

  throw new Error("è§†é¢‘ç”Ÿæˆè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•");
}

// å¤„ç†video-to-videoç”Ÿæˆï¼ˆä½¿ç”¨ gen4_aleph æ¨¡å‹ï¼‰
async function processVideoToVideo(videoUrl: string, prompt: string, options: { model: string, duration: number, ratio: string }) {
  console.log("ğŸ¬ Starting video-to-video processing:", { videoUrl, prompt, options });

  const modelFallbacks = getVideoToVideoModelFallbacks();
  let lastError: any = null;

  // å°è¯•æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹ï¼ˆç›®å‰åªæœ‰ gen4_alephï¼‰
  for (const modelToTry of modelFallbacks) {
    try {
      console.log(`ğŸ“‹ Trying model: ${modelToTry}`);

      const requestBody: any = {
        videoUri: videoUrl,
        promptText: prompt,
        model: modelToTry,
        ratio: validateAndFixRatio(options.ratio),
        duration: options.duration
      };

      console.log("ğŸ“¤ Sending video-to-video request:", requestBody);

      const response = await fetch(`${RUNWAY_API_BASE_URL}/video_to_video`, {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${RUNWAY_API_KEY}`,
          "Content-Type": "application/json",
          "X-Runway-Version": "2024-11-06"
        },
        body: JSON.stringify(requestBody)
      });

      const responseText = await response.text();

      if (!response.ok) {
        console.error(`âŒ Model ${modelToTry} failed:`, response.status, responseText);

        // æ£€æŸ¥æ˜¯å¦æ˜¯æ¨¡å‹ä¸å¯ç”¨é”™è¯¯
        if (response.status === 403 && responseText.includes('not available')) {
          console.log(`âš ï¸ Model ${modelToTry} not available, trying next model...`);
          lastError = new Error(`Model ${modelToTry} not available`);
          continue; // å°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
        }

        // å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
        throw new Error(`è§†é¢‘ç‰¹æ•ˆå¤„ç†å¤±è´¥: ${responseText}`);
      }

      // æˆåŠŸï¼
      const taskData = JSON.parse(responseText);
      console.log(`âœ… Successfully created task with model ${modelToTry}:`, taskData.id);

      // è¿”å›ä»»åŠ¡æ•°æ®ä»¥ç»§ç»­å¤„ç†
      return taskData;

    } catch (error: any) {
      console.error(`âŒ Error with model ${modelToTry}:`, error.message);
      lastError = error;

      // å¦‚æœä¸æ˜¯æ¨¡å‹ä¸å¯ç”¨é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
      if (!error.message.includes('not available')) {
        throw error;
      }
    }
  }

  // æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥äº†
  console.error("âŒ All models failed, last error:", lastError);
  throw new Error("æ‰€æœ‰å¯ç”¨æ¨¡å‹éƒ½æ— æ³•å¤„ç†æ­¤è¯·æ±‚ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ Runway API è´¦æˆ·æƒé™æˆ–è”ç³»æ”¯æŒ");
}

// è¾…åŠ©å‡½æ•°ï¼šç»§ç»­å¤„ç† video-to-video ä»»åŠ¡
async function finishVideoToVideoTask(taskData: any) {
  console.log("ğŸ“‹ Video-to-video task created:", taskData.id);

  // è½®è¯¢ç­‰å¾…ä»»åŠ¡å®Œæˆ
  const videoUrl_result = await waitForVideoGeneration(taskData.id);
  
  // ä¸‹è½½å¹¶å­˜å‚¨è§†é¢‘åˆ°Supabase Storage
  console.log("ğŸ’¾ Downloading and storing processed video...");
  const videoResponse = await fetch(videoUrl_result);
  if (!videoResponse.ok) {
    console.error("âŒ Failed to download processed video:", videoResponse.status);
    throw new Error("è§†é¢‘ä¸‹è½½å¤±è´¥ï¼Œè¯·é‡æ–°å°è¯•");
  }

  const videoBuffer = Buffer.from(await videoResponse.arrayBuffer());
  const storageUrl = await putAndGetUrl(
    `runway/${crypto.randomUUID()}.mp4`, 
    videoBuffer, 
    "video/mp4"
  );

  console.log("âœ… Video-to-video processed successfully:", storageUrl);
  return { url: storageUrl };
}

// çº¯æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆï¼ˆç›´æ¥ä½¿ç”¨é»˜è®¤å›¾ç‰‡æ–¹æ¡ˆï¼‰
async function generateTextToVideo(prompt: string, options: { duration: number, ratio: string, model: string }) {
  console.log("ğŸ¬ Starting text-to-video generation using default image approach:", { prompt, options });
  
  // Runway APIåªæ”¯æŒimage_to_videoï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥ä½¿ç”¨é»˜è®¤å›¾ç‰‡æ–¹æ¡ˆ
  return await generateWithDefaultImage(prompt, options);
}

// VEOæ¨¡å‹ä¸“ç”¨ï¼šä½¿ç”¨ä¸­æ€§èµ·å§‹å¸§ç”Ÿæˆè§†é¢‘
async function generateTextToVideoVEO(options: { prompt: string, duration: number, ratio: string, model: string }) {
  const { prompt, duration, ratio, model } = options;
  
  console.log("ğŸ¬ VEO generation with neutral start frame:", { 
    prompt: prompt.substring(0, 100) + "...", 
    duration, 
    ratio, 
    model 
  });
  
  try {
    // åˆ›å»ºä¸€ä¸ªå®Œæ•´å°ºå¯¸çš„ä¸­æ€§ç°è‰²æ¸å˜å›¾ç‰‡ï¼ˆé¿å…è§¦å‘å†…å®¹å®¡æ ¸ï¼‰
    const neutralStartFrame = createNeutralStartFrame(ratio);
    
    const requestBody = {
      promptText: prompt,
      promptImage: neutralStartFrame, // ä½¿ç”¨ä¸­æ€§èµ·å§‹å¸§
      model: model,
      ratio: validateAndFixRatioImageToVideo(ratio),
      duration: duration
    };

    console.log("ğŸ“¤ Sending VEO generation request with neutral frame:", {
      promptLength: prompt.length,
      model,
      ratio: requestBody.ratio,
      duration
    });

    const response = await fetchWithRetry(`${RUNWAY_API_BASE_URL}/image_to_video`, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${RUNWAY_API_KEY}`,
        "Content-Type": "application/json",
        "X-Runway-Version": "2024-11-06"
      },
      body: JSON.stringify(requestBody)
    }, 3);

    if (!response.ok) {
      const errorText = await response.text();
      console.error("âŒ Runway VEO generation API error:", response.status, errorText);
      throw new Error(`VEOè§†é¢‘ç”Ÿæˆå¤±è´¥: ${errorText}`);
    }

    const taskData = await response.json();
    console.log("ğŸ“‹ VEO generation task created:", taskData.id);

    // è½®è¯¢ç­‰å¾…ä»»åŠ¡å®Œæˆ
    const videoUrl = await waitForVideoGeneration(taskData.id);
    
    // ä¸‹è½½å¹¶å­˜å‚¨è§†é¢‘åˆ°Supabase Storage
    console.log("ğŸ’¾ Downloading and storing VEO video...");
    const videoResponse = await fetch(videoUrl);
    if (!videoResponse.ok) {
      console.error("âŒ Failed to download VEO video:", videoResponse.status);
      throw new Error("VEOè§†é¢‘ä¸‹è½½å¤±è´¥");
    }

    const videoBuffer = Buffer.from(await videoResponse.arrayBuffer());
    const storageUrl = await putAndGetUrl(
      `runway-veo/${crypto.randomUUID()}.mp4`, 
      videoBuffer, 
      "video/mp4"
    );

    console.log("âœ… VEO video stored successfully:", storageUrl);
    return storageUrl;

  } catch (error) {
    console.error("âŒ VEO generation failed:", error);
    throw new Error(`VEOè§†é¢‘ç”Ÿæˆå¤±è´¥: ${(error as Error).message}`);
  }
}

// åˆ›å»ºä¸­æ€§èµ·å§‹å¸§ï¼ˆç°è‰²æ¸å˜ï¼Œé¿å…è§¦å‘å†…å®¹å®¡æ ¸ï¼‰
function createNeutralStartFrame(ratio: string): string {
  // Runway API ä¸æ”¯æŒ SVGï¼Œç›´æ¥ä½¿ç”¨ç®€å•çš„ PNG data URI
  // è¿™æ˜¯ä¸€ä¸ª 1x1 åƒç´ çš„æ·±ç°è‰² PNG å›¾ç‰‡ï¼ŒRunway ä¼šè‡ªåŠ¨ç¼©æ”¾åˆ°æ‰€éœ€å°ºå¯¸
  const neutralPngDataUri = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mM0NDRkAAAAAgIBXBBTigAAAABJRU5ErkJggg==";

  console.log("ğŸ¨ Using neutral 1x1 PNG as start frame (Runway will scale automatically)");
  return neutralPngDataUri;
}

// ä½¿ç”¨é»˜è®¤å›¾ç‰‡ç”Ÿæˆè§†é¢‘ï¼ˆé€‚ç”¨äºçº¯æ–‡æœ¬ç”Ÿæˆï¼‰
async function generateWithDefaultImage(prompt: string, options: { duration: number, ratio: string, model: string }) {
  console.log("ğŸ¨ Using default image for video generation");
  
  try {
    // ä½¿ç”¨ä¸€ä¸ªç®€å•çš„PNGå›¾ç‰‡data URIï¼ˆ1x1åƒç´ ï¼Œæ·±è“è‰²ï¼‰
    const defaultImageUrl = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==";
    
    const requestBody = {
      promptText: prompt,
      promptImage: defaultImageUrl,
      model: selectModelForTask('image_to_video'), // ä½¿ç”¨image-to-videoæ¨¡å‹
      ratio: validateAndFixRatioImageToVideo(options.ratio),
      duration: options.duration
    };

    console.log("ğŸ“¤ Sending default image request:", { 
      ...requestBody, 
      promptImage: "1x1_png_data_uri",
      promptLength: prompt.length 
    });

    // æ·»åŠ é‡è¯•æœºåˆ¶å’Œæ›´é•¿çš„è¶…æ—¶æ—¶é—´
    const response = await fetchWithRetry(`${RUNWAY_API_BASE_URL}/image_to_video`, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${RUNWAY_API_KEY}`,
        "Content-Type": "application/json",
        "X-Runway-Version": "2024-11-06"
      },
      body: JSON.stringify(requestBody)
    }, 3);

    if (!response.ok) {
      const errorText = await response.text();
      console.error("âŒ Runway default image API error:", response.status, errorText);
      
      // å°è¯•ä½¿ç”¨æ›´ç®€å•çš„çº¯è‰²èƒŒæ™¯
      console.log("âš ï¸ Default image failed, trying solid color...");
      return await generateWithSolidBackground(prompt, options);
    }

    const taskData = await response.json();
    console.log("ğŸ“‹ Default gradient image task created:", taskData.id);

    // è½®è¯¢ç­‰å¾…ä»»åŠ¡å®Œæˆ
    const videoUrl = await waitForVideoGeneration(taskData.id);
    
    // ä¸‹è½½å¹¶å­˜å‚¨è§†é¢‘åˆ°Supabase Storage
    console.log("ğŸ’¾ Downloading and storing default image video...");
    const videoResponse = await fetch(videoUrl);
    if (!videoResponse.ok) {
      console.error("âŒ Failed to download default image video:", videoResponse.status);
      throw new Error("è§†é¢‘ä¸‹è½½å¤±è´¥ï¼Œè¯·é‡æ–°å°è¯•");
    }

    const videoBuffer = Buffer.from(await videoResponse.arrayBuffer());
    const storageUrl = await putAndGetUrl(
      `runway/${crypto.randomUUID()}.mp4`, 
      videoBuffer, 
      "video/mp4"
    );

    console.log("âœ… Default image video stored successfully:", storageUrl);
    return { url: storageUrl };

  } catch (error) {
    console.error("âŒ Default gradient image generation failed:", error);
    throw new Error("è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•");
  }
}

// ä½¿ç”¨çº¯è‰²èƒŒæ™¯ä½œä¸ºæœ€åçš„å¤‡é€‰æ–¹æ¡ˆ
async function generateWithSolidBackground(prompt: string, options: { duration: number, ratio: string, model: string }) {
  console.log("ğŸ¨ Using solid color background for video generation");
  
  try {
    // ä½¿ç”¨ä¸€ä¸ªç®€å•çš„PNGå›¾ç‰‡data URIï¼ˆ1x1åƒç´ ï¼Œé»‘è‰²ï¼‰
    const solidImageUrl = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChAI9jU77yQAAAABJRU5ErkJggg==";
    
    const requestBody = {
      promptText: prompt,
      promptImage: solidImageUrl,
      model: selectModelForTask('image_to_video'), // ä½¿ç”¨image-to-videoæ¨¡å‹
      ratio: validateAndFixRatioImageToVideo(options.ratio),
      duration: options.duration
    };

    console.log("ğŸ“¤ Sending solid background request:", { 
      ...requestBody, 
      promptImage: "1x1_black_png_data_uri" 
    });

    const response = await fetchWithRetry(`${RUNWAY_API_BASE_URL}/image_to_video`, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${RUNWAY_API_KEY}`,
        "Content-Type": "application/json",
        "X-Runway-Version": "2024-11-06"
      },
      body: JSON.stringify(requestBody)
    }, 3);

    if (!response.ok) {
      const errorText = await response.text();
      console.error("âŒ Runway solid background API error:", response.status, errorText);
      throw new Error("è§†é¢‘ç”ŸæˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•");
    }

    const taskData = await response.json();
    console.log("ğŸ“‹ Solid background task created:", taskData.id);

    // è½®è¯¢ç­‰å¾…ä»»åŠ¡å®Œæˆ
    const videoUrl = await waitForVideoGeneration(taskData.id);
    
    // ä¸‹è½½å¹¶å­˜å‚¨è§†é¢‘åˆ°Supabase Storage
    console.log("ğŸ’¾ Downloading and storing solid background video...");
    const videoResponse = await fetch(videoUrl);
    if (!videoResponse.ok) {
      console.error("âŒ Failed to download solid background video:", videoResponse.status);
      throw new Error("è§†é¢‘ä¸‹è½½å¤±è´¥ï¼Œè¯·é‡æ–°å°è¯•");
    }

    const videoBuffer = Buffer.from(await videoResponse.arrayBuffer());
    const storageUrl = await putAndGetUrl(
      `runway/${crypto.randomUUID()}.mp4`, 
      videoBuffer, 
      "video/mp4"
    );

    console.log("âœ… Solid background video stored successfully:", storageUrl);
    return { url: storageUrl };

  } catch (error) {
    console.error("âŒ Solid background generation failed:", error);
    throw new Error("è§†é¢‘ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•");
  }
}

// é•¿è§†é¢‘ç”Ÿæˆä¸»å‡½æ•° - åŸºäºLLMè§„åˆ’å™¨ + Runwayè¿ç»­ç”Ÿæˆ
export async function generateLongVideoRunway(options: RunwayLongVideoOptions) {
  const { prompt, attachedImages, jobId, shotPlan: providedShotPlan, model, onProgress } = options;
  
  console.log("ğŸ¬ Starting long video generation:", { 
    jobId, 
    prompt: prompt.substring(0, 100) + "...", 
    imagesCount: attachedImages.length,
    hasShotPlan: !!providedShotPlan
  });

  try {
    let shotPlan;
    
    if (providedShotPlan) {
      // ä½¿ç”¨æä¾›çš„é•œå¤´è§„åˆ’
      shotPlan = providedShotPlan;
      console.log("ğŸ“‹ Using provided shot plan:", {
        totalShots: shotPlan.shots?.length || 0,
        totalDuration: shotPlan.total_seconds || 0
      });
      
      await onProgress?.({ 
        percentage: 5, 
        step: "ä½¿ç”¨ç¡®è®¤è§„åˆ’", 
        message: "æ­£åœ¨ä½¿ç”¨æ‚¨ç¡®è®¤çš„é•œå¤´è§„åˆ’..." 
      });
    } else {
      // æ­¥éª¤1: ä½¿ç”¨LLMè§„åˆ’å™¨åˆ†æå’Œè§„åˆ’é•œå¤´
      await onProgress?.({ 
        percentage: 5, 
        step: "æ™ºèƒ½åˆ†æ", 
        message: "æ­£åœ¨ä½¿ç”¨AIåˆ†ææç¤ºè¯å¹¶è§„åˆ’é•œå¤´åºåˆ—..." 
      });
      
      const { generateShotPlan } = await import("@/lib/llm/shot-planner");
      shotPlan = await generateShotPlan(prompt, 65, "1280:768"); // é»˜è®¤65ç§’ï¼ŒRunway image_to_videoæ”¯æŒçš„æ¯”ä¾‹
      
      console.log("ğŸ“‹ Generated shot plan:", {
        totalShots: shotPlan.shots.length,
        totalDuration: shotPlan.total_seconds,
        shots: shotPlan.shots.map(s => ({ id: s.id, duration: s.duration_s, camera: s.camera }))
      });
    }

    // æ£€æŸ¥æ˜¯å¦ä½¿ç”¨VEOæ¨¡å‹
    const isVeoModel = model && (model.includes('veo') || model.includes('VEO'));
    
    // æ­¥éª¤2: å‡†å¤‡é¦–å¸§å…³é”®å¸§
    await onProgress?.({ 
      percentage: 10, 
      step: "å‡†å¤‡é¦–å¸§", 
      message: "æ­£åœ¨å‡†å¤‡é¦–å¸§å…³é”®å¸§..." 
    });
    
    let currentKeyframeUrl: string | null = null;
    let firstShotGenerated = false; // æ ‡è®°ç¬¬ä¸€ä¸ªé•œå¤´æ˜¯å¦å·²ç”Ÿæˆ
    
    if (attachedImages.length > 0) {
      // ä½¿ç”¨ç”¨æˆ·ä¸Šä¼ çš„ç¬¬ä¸€å¼ å›¾ç‰‡ä½œä¸ºé¦–å¸§
      currentKeyframeUrl = attachedImages[0];
      console.log("ğŸ–¼ï¸ Using user uploaded image as first keyframe");
    } else if (isVeoModel) {
      // VEOæ¨¡å‹ï¼šç¬¬ä¸€ä¸ªé•œå¤´ä½¿ç”¨çº¯æ–‡æœ¬ç”Ÿæˆï¼Œç„¶åæå–å°¾å¸§
      console.log("ğŸ¬ VEO model - will generate first shot with text-to-video");
      // ä¸è®¾ç½®currentKeyframeUrlï¼Œåœ¨å¾ªç¯ä¸­ç‰¹æ®Šå¤„ç†ç¬¬ä¸€ä¸ªé•œå¤´
    } else {
      // éVEOæ¨¡å‹ï¼šä½¿ç”¨é»˜è®¤å›¾ç‰‡æ–¹æ¡ˆç”Ÿæˆé¦–å¸§
      console.log("ğŸ¨ Generating first keyframe with T2I");
      const firstShotPrompt = shotPlan.shots[0]?.prompt || "A cinematic establishing shot";
      
      const firstFrameResult = await generateWithDefaultImage(firstShotPrompt, {
        duration: 5,
        ratio: shotPlan.ratio,
        model: selectModelForTask('image_to_video')
      });
      
      const { extractLastFrame, downloadFile, fileToDataUri } = await import("@/lib/video/ffmpeg-utils");
      const tempVideoPath = `/tmp/${crypto.randomUUID()}.mp4`;
      await downloadFile(firstFrameResult.url, tempVideoPath);
      const firstFramePath = await extractLastFrame(tempVideoPath);
      currentKeyframeUrl = await fileToDataUri(firstFramePath);
    }

    // æ­¥éª¤3: æŒ‰é•œå¤´é¡ºåºç”Ÿæˆè§†é¢‘ç‰‡æ®µ
    const generatedSegments: string[] = [];
    const totalShots = shotPlan.shots.length;
    
    for (let i = 0; i < totalShots; i++) {
      const shot = shotPlan.shots[i];
      const progressBase = 15 + (i * 70) / totalShots;
      
      await onProgress?.({ 
        percentage: progressBase, 
        step: `ç”Ÿæˆé•œå¤´ ${i + 1}/${totalShots}`, 
        message: `æ­£åœ¨ç”Ÿæˆé•œå¤´${i + 1}ï¼š${shot.camera}é•œå¤´ï¼Œ${shot.duration_s}ç§’` 
      });

      try {
        let segmentUrl: string;
        
        // VEOæ¨¡å‹ç‰¹æ®Šå¤„ç†ï¼šç¬¬ä¸€ä¸ªé•œå¤´ç”¨text-to-videoï¼Œåç»­é•œå¤´ç”¨image-to-videoä¿è¯è¿è´¯æ€§
        if (isVeoModel && i === 0 && !currentKeyframeUrl) {
          // VEOç¬¬ä¸€ä¸ªé•œå¤´ï¼šä½¿ç”¨çº¯æ–‡æœ¬ç”Ÿæˆ
          console.log(`ğŸ¬ VEO first shot - using text-to-video`);
          segmentUrl = await generateTextToVideoVEO({
            prompt: shot.prompt,
            duration: shot.duration_s,
            ratio: shotPlan.ratio,
            model: model || 'veo3.1'
          });
        } else {
          // å…¶ä»–æƒ…å†µï¼šä½¿ç”¨å…³é”®å¸§ç”Ÿæˆï¼ˆä¿è¯è¿è´¯æ€§ï¼‰
          console.log(`ğŸ¬ Shot ${i + 1} - using image-to-video with keyframe`);
          segmentUrl = await generateVideoSegmentWithKeyframe({
            prompt: shot.prompt,
            keyframeUrl: currentKeyframeUrl!,
            duration: shot.duration_s,
            ratio: shotPlan.ratio,
            model: model // ä¼ é€’æ¨¡å‹å‚æ•°ï¼ˆVEOæˆ–å…¶ä»–ï¼‰
          });
        }
        
        generatedSegments.push(segmentUrl);
        console.log(`âœ… Generated shot ${i + 1}/${totalShots}:`, segmentUrl);
        
        // æå–å°¾å¸§ä½œä¸ºä¸‹ä¸€ä¸ªé•œå¤´çš„é¦–å¸§ï¼ˆä¿è¯è¿è´¯æ€§ï¼‰
        if (i < totalShots - 1) {
          await onProgress?.({ 
            percentage: progressBase + (70 / totalShots) * 0.5, 
            step: `æå–è¿æ¥å¸§`, 
            message: `æ­£åœ¨æå–é•œå¤´${i + 1}çš„å°¾å¸§ç”¨äºè¿ç»­æ€§...` 
          });
          
          currentKeyframeUrl = await extractAndConvertLastFrame(segmentUrl);
        }
        
        await onProgress?.({ 
          percentage: progressBase + (70 / totalShots), 
          step: `é•œå¤´ ${i + 1} å®Œæˆ`, 
          message: `é•œå¤´${i + 1}ç”Ÿæˆå®Œæˆ` 
        });
        
      } catch (error) {
        console.error(`âŒ Failed to generate shot ${i + 1}:`, error);
        throw new Error(`é•œå¤´${i + 1}ç”Ÿæˆå¤±è´¥: ${(error as Error).message}`);
      }
    }

    // æ­¥éª¤4: æ‹¼æ¥æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
    await onProgress?.({ 
      percentage: 90, 
      step: "æ‹¼æ¥è§†é¢‘", 
      message: "æ­£åœ¨æ‹¼æ¥æ‰€æœ‰é•œå¤´ä¸ºå®Œæ•´é•¿è§†é¢‘..." 
    });

    const finalVideoUrl = await stitchVideoSegments(generatedSegments, jobId);
    
    await onProgress?.({ 
      percentage: 100, 
      step: "å®Œæˆ", 
      message: `é•¿è§†é¢‘ç”Ÿæˆå®Œæˆï¼æ€»æ—¶é•¿: ${shotPlan.total_seconds}ç§’` 
    });

    console.log("ğŸ‰ Long video generation completed:", finalVideoUrl);
    return { url: finalVideoUrl };

  } catch (error) {
    console.error("âŒ Long video generation failed:", error);
    throw new Error(`é•¿è§†é¢‘ç”Ÿæˆå¤±è´¥: ${(error as Error).message}`);
  }
}

// è§„åˆ’è§†é¢‘ç‰‡æ®µ
async function planVideoSegments(prompt: string, attachedImages: string[]): Promise<VideoSegment[]> {
  const segments: VideoSegment[] = [];
  
  // å¦‚æœæœ‰é™„åŠ å›¾ç‰‡ï¼Œä¸ºæ¯å¼ å›¾ç‰‡åˆ›å»ºä¸€ä¸ªç‰‡æ®µ
  if (attachedImages.length > 0) {
    attachedImages.forEach((imageUrl, index) => {
      segments.push({
        id: `segment-${index + 1}`,
        prompt: `${prompt} - ç¬¬${index + 1}éƒ¨åˆ†`,
        imageUrl,
        duration: 5, // æ¯ä¸ªç‰‡æ®µ5ç§’
        order: index + 1
      });
    });
  } else {
    // å¦‚æœæ²¡æœ‰é™„åŠ å›¾ç‰‡ï¼Œæ ¹æ®æç¤ºè¯åˆ›å»ºå¤šä¸ªç‰‡æ®µ
    const segmentCount = Math.max(2, Math.min(6, Math.ceil(prompt.length / 100))); // 2-6ä¸ªç‰‡æ®µ
    
    for (let i = 0; i < segmentCount; i++) {
      segments.push({
        id: `segment-${i + 1}`,
        prompt: `${prompt} - ç‰‡æ®µ${i + 1}`,
        duration: 5,
        order: i + 1
      });
    }
  }
  
  return segments;
}

// ä½¿ç”¨å…³é”®å¸§ç”Ÿæˆè§†é¢‘ç‰‡æ®µ
async function generateVideoSegmentWithKeyframe({
  prompt,
  keyframeUrl,
  duration,
  ratio,
  model
}: {
  prompt: string;
  keyframeUrl: string;
  duration: number;
  ratio: string;
  model?: string;
}): Promise<string> {
  console.log(`ğŸ¬ Generating video segment:`, { prompt: prompt.substring(0, 50) + "...", duration, ratio, model });
  
  // å°è¯•æœ€å¤š3æ¬¡ç”Ÿæˆ
  for (let attempt = 1; attempt <= 3; attempt++) {
    try {
      // å¦‚æœæ˜¯å› ä¸ºBAD_OUTPUTé”™è¯¯é‡è¯•ï¼Œä½¿ç”¨æç®€æç¤ºè¯
      let adjustedPrompt = prompt;
      if (attempt > 1) {
        if (attempt === 2) {
          // ç¬¬äºŒæ¬¡å°è¯•ï¼šç§»é™¤å¤æ‚æè¿°
          adjustedPrompt = prompt
            .replace(/\b(subtle|subtly|gently|softly|slightly|faintly|ethereal|mystical|magical|pulsating|shimmering)\b/gi, '')
            .replace(/,\s*their[^,]+,/gi, ',')
            .replace(/\.\s*[A-Z][^.]*motion blur[^.]*\./gi, '.')
            .replace(/\s+/g, ' ')
            .trim();
        } else if (attempt === 3) {
          // ç¬¬ä¸‰æ¬¡å°è¯•ï¼šä½¿ç”¨æç®€æè¿°
          adjustedPrompt = "A young woman in traditional robe runs up stone steps, POV camera";
        }
        
        console.log(`ğŸ”„ Attempt ${attempt}: Simplified prompt from ${prompt.length} to ${adjustedPrompt.length} characters`);
        console.log(`ğŸ”„ New prompt: ${adjustedPrompt}`);
      }
      
      return await generateSingleVideoSegment({ prompt: adjustedPrompt, keyframeUrl, duration, ratio, model });
    } catch (error) {
      console.warn(`âš ï¸ Video segment generation attempt ${attempt} failed:`, (error as Error).message);
      
      // å¦‚æœæ˜¯BAD_OUTPUTé”™è¯¯ï¼Œç»§ç»­é‡è¯•ï¼›å…¶ä»–é”™è¯¯ç«‹å³å¤±è´¥
      const isBadOutputError = (error as Error).message.includes('RUNWAY_BAD_OUTPUT') || (error as Error).message.includes('INTERNAL.BAD_OUTPUT.CODE01');
      
      console.log(`ğŸ” Error analysis:`, {
        attempt,
        isBadOutputError,
        errorMessage: (error as Error).message,
        willRetry: attempt < 3 && isBadOutputError
      });
      
      if (attempt === 3 || !isBadOutputError) {
        console.log(`âŒ Giving up after ${attempt} attempts or non-BAD_OUTPUT error`);
        throw error; // æœ€åä¸€æ¬¡å°è¯•å¤±è´¥æˆ–éBAD_OUTPUTé”™è¯¯ï¼ŒæŠ›å‡ºé”™è¯¯
      }
      
      // ç­‰å¾…åé‡è¯•
      const delay = 2000 * attempt; // é€’å¢å»¶è¿Ÿï¼š2s, 4s
      console.log(`â³ BAD_OUTPUT detected, waiting ${delay}ms before retry ${attempt + 1} with simplified prompt...`);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  
  throw new Error("æ‰€æœ‰é‡è¯•å°è¯•éƒ½å·²å¤±è´¥");
}

// å•æ¬¡è§†é¢‘ç‰‡æ®µç”Ÿæˆ
async function generateSingleVideoSegment({
  prompt,
  keyframeUrl,
  duration,
  ratio,
  model
}: {
  prompt: string;
  keyframeUrl: string;
  duration: number;
  ratio: string;
  model?: string;
}): Promise<string> {
  // å¦‚æœkeyframeUrlæ˜¯data URIï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™éœ€è¦è½¬æ¢
  let promptImage = keyframeUrl;
  if (!keyframeUrl.startsWith('data:')) {
    // ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºdata URI
    const { downloadFile, fileToDataUri } = await import("@/lib/video/ffmpeg-utils");
    const tempImagePath = `/tmp/${crypto.randomUUID()}.png`;
    await downloadFile(keyframeUrl, tempImagePath);
    promptImage = await fileToDataUri(tempImagePath);
  }
  
  const requestBody = {
    promptText: prompt,
    promptImage: promptImage,
    model: selectModelForTask('image_to_video', model), // ä½¿ç”¨æä¾›çš„æ¨¡å‹æˆ–é»˜è®¤æ¨¡å‹
    ratio: validateAndFixRatioImageToVideo(ratio),
    duration: duration
  };

  console.log("ğŸ“¤ Sending video generation request to Runway:", {
    promptLength: prompt.length,
    promptPreview: prompt.substring(0, 100) + "...",
    duration,
    ratio,
    hasImage: true,
    imageType: keyframeUrl.startsWith('data:') ? 'data_uri' : 'url'
  });

  const response = await fetchWithRetry(`${RUNWAY_API_BASE_URL}/image_to_video`, {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${RUNWAY_API_KEY}`,
      "Content-Type": "application/json",
      "X-Runway-Version": "2024-11-06"
    },
    body: JSON.stringify(requestBody)
  }, 3);

  if (!response.ok) {
    const errorText = await response.text();
    console.error("âŒ Runway video generation API error:", response.status, errorText);
    throw new Error("è§†é¢‘ç”ŸæˆæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•");
  }

  const taskData = await response.json();
  console.log("ğŸ“‹ Video generation task created:", taskData.id);

  // è½®è¯¢ç­‰å¾…ä»»åŠ¡å®Œæˆ
  const videoUrl = await waitForVideoGeneration(taskData.id);
  
  // ä¸‹è½½å¹¶å­˜å‚¨è§†é¢‘åˆ°Supabase Storage
  console.log("ğŸ’¾ Downloading and storing generated video...");
  const videoResponse = await fetch(videoUrl);
  if (!videoResponse.ok) {
    console.error("âŒ Failed to download generated video:", videoResponse.status);
    throw new Error("è§†é¢‘ä¸‹è½½å¤±è´¥ï¼Œè¯·é‡æ–°å°è¯•");
  }

  const videoBuffer = Buffer.from(await videoResponse.arrayBuffer());
  const storageUrl = await putAndGetUrl(
    `runway/${crypto.randomUUID()}.mp4`, 
    videoBuffer, 
    "video/mp4"
  );

  console.log("âœ… Video segment stored successfully:", storageUrl);
  return storageUrl;
}

// æå–è§†é¢‘å°¾å¸§å¹¶è½¬æ¢ä¸ºå¯ç”¨çš„URL
async function extractAndConvertLastFrame(videoUrl: string): Promise<string> {
  try {
    const { downloadFile, extractLastFrame, fileToDataUri } = await import("@/lib/video/ffmpeg-utils");
    
    // ä¸‹è½½è§†é¢‘
    const tempVideoPath = `/tmp/${crypto.randomUUID()}.mp4`;
    await downloadFile(videoUrl, tempVideoPath);
    
    // æå–å°¾å¸§
    const lastFramePath = await extractLastFrame(tempVideoPath);
    
    // è½¬æ¢ä¸ºdata URI
    const dataUri = await fileToDataUri(lastFramePath);
    
    console.log("âœ… Last frame extracted and converted to data URI");
    return dataUri;
    
  } catch (error) {
    console.error("âŒ Failed to extract and convert last frame:", error);
    throw new Error(`å°¾å¸§æå–å¤±è´¥: ${(error as Error).message}`);
  }
}

// æ‹¼æ¥è§†é¢‘ç‰‡æ®µ
async function stitchVideoSegments(segmentUrls: string[], jobId: string): Promise<string> {
  console.log("ğŸ”— Stitching video segments:", segmentUrls.length);
  
  try {
    const { downloadFile, concatVideos } = await import("@/lib/video/ffmpeg-utils");
    
    // ä¸‹è½½æ‰€æœ‰ç‰‡æ®µ
    const tempDir = `/tmp/long-video-${jobId}`;
    const segmentPaths: string[] = [];
    
    for (let i = 0; i < segmentUrls.length; i++) {
      const segmentPath = `${tempDir}/segment_${i + 1}.mp4`;
      await downloadFile(segmentUrls[i], segmentPath);
      segmentPaths.push(segmentPath);
    }
    
    // æ‹¼æ¥è§†é¢‘
    const stitchedPath = `${tempDir}/stitched.mp4`;
    await concatVideos(segmentPaths, stitchedPath);
    
    // ä¸Šä¼ æœ€ç»ˆè§†é¢‘åˆ°å­˜å‚¨
    const fs = await import('fs');
    const finalBuffer = await fs.promises.readFile(stitchedPath);
    const finalUrl = await putAndGetUrl(
      `long-video/${jobId}-final.mp4`, 
      finalBuffer, 
      "video/mp4"
    );
    
    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    await fs.promises.rm(tempDir, { recursive: true, force: true });
    
    console.log("âœ… Video segments stitched successfully:", finalUrl);
    return finalUrl;
    
  } catch (error) {
    console.error("âŒ Video stitching failed:", error);
    throw new Error(`è§†é¢‘æ‹¼æ¥å¤±è´¥: ${(error as Error).message}`);
  }
}

// åˆå¹¶è§†é¢‘ç‰‡æ®µ
async function mergeVideoSegments(segments: VideoSegment[], jobId: string): Promise<string> {
  console.log("ğŸ”— Merging video segments:", segments.length);
  
  try {
    // è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€åŒ–çš„åˆå¹¶ç­–ç•¥ï¼š
    // 1. å¦‚æœåªæœ‰ä¸€ä¸ªç‰‡æ®µï¼Œç›´æ¥è¿”å›
    // 2. å¦‚æœæœ‰å¤šä¸ªç‰‡æ®µï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç‰‡æ®µä½œä¸ºåŸºç¡€ï¼Œå…¶ä»–ç‰‡æ®µé€šè¿‡video-to-videoè¿›è¡Œè¿æ¥
    
    if (segments.length === 1) {
      console.log("âœ… Single segment, no merging needed");
      return segments[0].videoUrl!;
    }
    
    // å¯¹äºå¤šä¸ªç‰‡æ®µï¼Œæˆ‘ä»¬éœ€è¦å®ç°è§†é¢‘æ‹¼æ¥
    // ç”±äºRunway APIç›®å‰ä¸ç›´æ¥æ”¯æŒè§†é¢‘æ‹¼æ¥ï¼Œæˆ‘ä»¬é‡‡ç”¨ä»¥ä¸‹ç­–ç•¥ï¼š
    // 1. ä½¿ç”¨ç¬¬ä¸€ä¸ªè§†é¢‘ä½œä¸ºåŸºç¡€
    // 2. é€æ­¥ä½¿ç”¨video-to-videoå°†åç»­ç‰‡æ®µçš„å†…å®¹èåˆè¿›å»
    
    let currentVideo = segments[0].videoUrl!;
    
    for (let i = 1; i < segments.length; i++) {
      const nextSegment = segments[i];
      console.log(`ğŸ”— Merging segment ${i + 1} into current video...`);
      
      // ä½¿ç”¨video-to-videoå°†ä¸‹ä¸€ä¸ªç‰‡æ®µçš„å†…å®¹èåˆåˆ°å½“å‰è§†é¢‘ä¸­
      const mergePrompt = `ç»§ç»­è§†é¢‘å†…å®¹ï¼Œèåˆä»¥ä¸‹åœºæ™¯: ${nextSegment.prompt}`;
      
      try {
        const mergedResult = await processVideoToVideo(
          currentVideo, 
          mergePrompt, 
          { model: selectModelForTask('video_to_video'), duration: 10, ratio: "1280:720" }
        );
        currentVideo = mergedResult.url;
        console.log(`âœ… Merged segment ${i + 1}`);
      } catch (error) {
        console.warn(`âš ï¸ Failed to merge segment ${i + 1}, using original video:`, error);
        // å¦‚æœåˆå¹¶å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰è§†é¢‘
      }
    }
    
    // å­˜å‚¨æœ€ç»ˆåˆå¹¶çš„è§†é¢‘
    const finalFileName = `long-video/${jobId}-final.mp4`;
    
    // ä¸‹è½½å½“å‰è§†é¢‘å¹¶é‡æ–°ä¸Šä¼ åˆ°æœ€ç»ˆä½ç½®
    const videoResponse = await fetch(currentVideo);
    if (!videoResponse.ok) {
      throw new Error("æ— æ³•ä¸‹è½½åˆå¹¶åçš„è§†é¢‘");
    }
    
    const videoBuffer = Buffer.from(await videoResponse.arrayBuffer());
    const finalUrl = await putAndGetUrl(finalFileName, videoBuffer, "video/mp4");
    
    console.log("âœ… Final long video stored:", finalUrl);
    return finalUrl;
    
  } catch (error) {
    console.error("âŒ Video merging failed:", error);
    throw new Error(`è§†é¢‘åˆå¹¶å¤±è´¥: ${(error as Error).message}`);
  }
}

// Act-Two è§’è‰²åŠŸèƒ½æ¥å£
interface FaceSwapOptions {
  drivingVideoUrl: string;
  characterImageUrl: string;
  prompt: string;
  duration: number;
  ratio: string;
  model: string;
}

// Act-Two è§’è‰²åŠŸèƒ½ - ä½¿ç”¨ character_performance ç«¯ç‚¹
async function generateFaceSwapWithActTwo(options: FaceSwapOptions) {
  const { drivingVideoUrl, characterImageUrl, prompt, duration, ratio, model } = options;

  console.log("ğŸ¬ Using Act-Two character performance API for face swap");

  try {
    // æ„å»º character_performance è¯·æ±‚ä½“
    const requestBody = {
      model: "act_two",
      ratio: validateAndFixRatio(ratio),
      character: {
        type: "image",
        uri: characterImageUrl
      },
      reference: {
        type: "video",
        uri: drivingVideoUrl
      },
      expressionIntensity: 3,
      bodyControl: true
    };

    console.log("ğŸ“¤ Sending Act-Two character_performance request:", {
      model: requestBody.model,
      ratio: requestBody.ratio,
      characterType: requestBody.character.type,
      referenceType: requestBody.reference.type,
      expressionIntensity: requestBody.expressionIntensity,
      bodyControl: requestBody.bodyControl
    });

    // è°ƒç”¨ character_performance ç«¯ç‚¹
    const response = await fetchWithRetry(`${RUNWAY_API_BASE_URL}/character_performance`, {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${RUNWAY_API_KEY}`,
        "Content-Type": "application/json",
        "X-Runway-Version": "2024-11-06"
      },
      body: JSON.stringify(requestBody)
    }, 3);

    if (!response.ok) {
      const errorText = await response.text();
      console.error("âŒ Act-Two character_performance API error:", response.status, errorText);

      // è§£æé”™è¯¯å¹¶æä¾›æ›´å¥½çš„é”™è¯¯ä¿¡æ¯
      if (errorText.includes("not available")) {
        throw new Error("Act-Two æ¨¡å‹æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•");
      } else if (errorText.includes("content policy")) {
        throw new Error("å†…å®¹ä¸ç¬¦åˆå¹³å°æ”¿ç­–ï¼Œè¯·è°ƒæ•´è§’è‰²ç´ æåé‡è¯•");
      }

      throw new Error("Act-Two è§’è‰²æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•");
    }

    const taskData = await response.json();
    console.log("ğŸ“‹ Act-Two character_performance task created:", taskData.id);

    // è½®è¯¢ç­‰å¾…ä»»åŠ¡å®Œæˆ
    const videoUrl = await waitForVideoGeneration(taskData.id);

    // ä¸‹è½½å¹¶å­˜å‚¨ç»“æœ
    console.log("ğŸ’¾ Downloading and storing Act-Two result...");
    const videoResponse = await fetch(videoUrl);
    if (!videoResponse.ok) {
      console.error("âŒ Failed to download Act-Two result:", videoResponse.status);
      throw new Error("è§’è‰²ç»“æœä¸‹è½½å¤±è´¥ï¼Œè¯·é‡æ–°å°è¯•");
    }

    const videoBuffer = Buffer.from(await videoResponse.arrayBuffer());
    const storageUrl = await putAndGetUrl(
      `runway/act-two/${crypto.randomUUID()}.mp4`,
      videoBuffer,
      "video/mp4"
    );

    console.log("âœ… Act-Two face swap result stored successfully:", storageUrl);
    return { url: storageUrl };

  } catch (error) {
    console.error("âŒ Act-Two face swap failed:", error);
    throw error;
  }
}

// æ”¹è¿›çš„å¤‡ç”¨è§’è‰²æ–¹æ¡ˆ
async function generateFaceSwapFallback(options: FaceSwapOptions) {
  const { drivingVideoUrl, characterImageUrl, prompt, duration, ratio, model } = options;

  console.log("ğŸ­ Using improved fallback face swap method");

  try {
    // æ–¹æ¡ˆ1ï¼šä½¿ç”¨video-to-videoï¼Œå°†è§’è‰²æè¿°èå…¥æç¤ºè¯
    const enhancedPrompt = `Transform the person in the video to look like the character from the reference image. ${prompt}. Maintain the original background, camera angles, and scene composition. Focus on changing only the person's appearance while preserving their movements and expressions.`;

    console.log("ğŸ“ Enhanced prompt for face swap:", enhancedPrompt.substring(0, 100) + "...");

    // ä½¿ç”¨video-to-videoç«¯ç‚¹ï¼Œå¹¶å°†è§’è‰²å›¾ç‰‡ä¿¡æ¯èå…¥å¤„ç†
    const result = await processVideoToVideoWithCharacter({
      videoUrl: drivingVideoUrl,
      characterImageUrl,
      prompt: enhancedPrompt,
      model,
      duration,
      ratio
    });

    return result;

  } catch (error) {
    console.error("âŒ Fallback face swap failed:", error);
    throw new Error(`è§’è‰²å¤„ç†å¤±è´¥: ${(error as Error).message}`);
  }
}

// å¸¦è§’è‰²å‚è€ƒçš„video-to-videoå¤„ç†
async function processVideoToVideoWithCharacter({
  videoUrl,
  characterImageUrl,
  prompt,
  model,
  duration,
  ratio
}: {
  videoUrl: string;
  characterImageUrl: string;
  prompt: string;
  model: string;
  duration: number;
  ratio: string;
}) {
  console.log("ğŸ¬ Processing video-to-video with character reference");

  // æ³¨æ„ï¼šç”±äºå½“å‰Runway APIé™åˆ¶ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥ä¼ å…¥è§’è‰²å›¾ç‰‡
  // è¿™æ˜¯ä¸€ä¸ªæ”¹è¿›çš„å®ç°ï¼Œä¸“æ³¨äºæ›´å¥½çš„æç¤ºè¯å·¥ç¨‹

  const requestBody: any = {
    videoUri: videoUrl,
    promptText: prompt,
    model: selectModelForTask('video_to_video', model),
    ratio: validateAndFixRatio(ratio),
    duration: duration, // æ·»åŠ durationå‚æ•°
    // æœªæ¥å¯èƒ½æ”¯æŒçš„å‚æ•°ï¼š
    // characterImageUri: characterImageUrl,
    // preserveBackground: true,
    // focusOnCharacter: true
  };

  console.log("ğŸ“¤ Sending enhanced video-to-video request:", {
    videoUri: "provided",
    promptLength: prompt.length,
    model,
    ratio
  });

  const response = await fetchWithRetry(`${RUNWAY_API_BASE_URL}/video_to_video`, {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${RUNWAY_API_KEY}`,
      "Content-Type": "application/json",
      "X-Runway-Version": "2024-11-06"
    },
    body: JSON.stringify(requestBody)
  });

  if (!response.ok) {
    const errorText = await response.text();
    console.error("âŒ Enhanced video-to-video API error:", response.status, errorText);

    // è§£æé”™è¯¯å¹¶æä¾›æ›´å¥½çš„é”™è¯¯ä¿¡æ¯
    if (errorText.includes("content policy")) {
      throw new Error("å†…å®¹ä¸ç¬¦åˆå¹³å°æ”¿ç­–ï¼Œè¯·è°ƒæ•´è§’è‰²ç´ æåé‡è¯•");
    } else if (errorText.includes("video format")) {
      throw new Error("è§†é¢‘æ ¼å¼ä¸æ”¯æŒï¼Œè¯·ä¸Šä¼ MP4æ ¼å¼çš„è§†é¢‘");
    } else if (errorText.includes("duration")) {
      throw new Error("è§†é¢‘æ—¶é•¿è¶…å‡ºé™åˆ¶ï¼Œè¯·ä¸Šä¼ 10ç§’ä»¥å†…çš„è§†é¢‘");
    }

    throw new Error("è§’è‰²å¤„ç†æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•");
  }

  const taskData = await response.json();
  console.log("ğŸ“‹ Enhanced video-to-video task created:", taskData.id);

  // è½®è¯¢ç­‰å¾…ä»»åŠ¡å®Œæˆ
  const videoResultUrl = await waitForVideoGeneration(taskData.id);

  // ä¸‹è½½å¹¶å­˜å‚¨è§†é¢‘åˆ°Supabase Storage
  console.log("ğŸ’¾ Downloading and storing face swap result...");
  const videoResponse = await fetch(videoResultUrl);
  if (!videoResponse.ok) {
    console.error("âŒ Failed to download face swap result:", videoResponse.status);
    throw new Error("è§’è‰²ç»“æœä¸‹è½½å¤±è´¥ï¼Œè¯·é‡æ–°å°è¯•");
  }

  const videoBuffer = Buffer.from(await videoResponse.arrayBuffer());
  const storageUrl = await putAndGetUrl(
    `runway/face-swap/${crypto.randomUUID()}.mp4`,
    videoBuffer,
    "video/mp4"
  );

  console.log("âœ… Face swap result stored successfully:", storageUrl);
  return { url: storageUrl };
}

// å¤„ç†å›ºå®šå›¾ç‰‡ + ç”¨æˆ·è§†é¢‘çš„ç‰¹æ®Šæƒ…å†µ
async function processVideoWithFixedImage(options: {
  videoUrl: string;
  imageUrl: string;
  prompt: string;
  duration: number;
  ratio: string;
  model?: string;
}) {
  const { videoUrl, imageUrl, prompt, duration, ratio, model } = options;
  
  console.log("ğŸ­ Processing video with fixed image:", { videoUrl, imageUrl, prompt, duration, ratio, model });

  try {
    // æ ¹æ®ç°æœ‰æˆåŠŸæ¡ˆä¾‹ï¼ŒRunwayä¸»è¦ä½¿ç”¨image_to_videoç«¯ç‚¹
    // ä»¥å›ºå®šå›¾ç‰‡ä¸ºåŸºç¡€ï¼Œåœ¨promptä¸­èå…¥ç”¨æˆ·è§†é¢‘çš„åŠ¨æ€æè¿°
    const enhancedPrompt = `${prompt}. Create dynamic video effects based on the provided image. Generate realistic motion, dramatic visual effects, and cinematic quality animation. The scene should have intense action, dynamic movement, and professional video production quality.`;
    
    console.log("ğŸ¯ Using image_to_video approach with enhanced prompt:", enhancedPrompt.substring(0, 150) + "...");

    // ä½¿ç”¨image_to_videoç«¯ç‚¹ï¼Œè¿™æ˜¯Runway APIçš„ä¸»è¦å·¥ä½œæ–¹å¼
    const requestBody = {
      promptText: enhancedPrompt,
      promptImage: imageUrl, // å›ºå®šçš„çˆ†ç‚¸å›¾ç‰‡ä½œä¸ºè§†è§‰åŸºç¡€
      model: selectModelForTask('image_to_video', model),
      ratio: validateAndFixRatio(ratio),
      duration: duration
    };

    console.log("ğŸ“¤ Sending image_to_video request with fixed image:", {
      promptText: requestBody.promptText.substring(0, 100) + "...",
      promptImage: "provided",
      model: requestBody.model,
      ratio: requestBody.ratio,
      duration: requestBody.duration
    });

    const response = await fetchWithRetry(`${RUNWAY_API_BASE_URL}/image_to_video`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${RUNWAY_API_KEY}`,
        'Content-Type': 'application/json',
        'X-Runway-Version': '2024-11-06'
      },
      body: JSON.stringify(requestBody)
    }, 3);

    if (!response.ok) {
      const error = await response.text();
      console.error("âŒ Runway image_to_video API error response:", error);
      throw new Error(`Runway API failed: ${response.status} ${error}`);
    }

    const taskData = await response.json();
    console.log("ğŸ“‹ Image_to_video task created:", taskData.id);

    // ç­‰å¾…è§†é¢‘ç”Ÿæˆå®Œæˆ
    const videoResultUrl = await waitForVideoGeneration(taskData.id);
    console.log("âœ… Video generated from fixed image:", videoResultUrl);

    return { url: videoResultUrl };
    
  } catch (error) {
    console.error("âŒ Failed to process video with fixed image:", error);
    throw new Error(`è§†é¢‘ç‰¹æ•ˆå¤„ç†å¤±è´¥: ${error instanceof Error ? error.message : String(error)}`);
  }
}

// å¤„ç†å›¾ç‰‡è½¬è§†é¢‘çš„åŠŸèƒ½
async function processImageToVideo(options: {
  imageUrl: string;
  prompt: string;
  duration: number;
  ratio: string;
  model?: string;
}) {
  const { imageUrl, prompt, duration, ratio, model } = options;
  
  console.log("ğŸ“¸ Processing image-to-video:", { imageUrl, prompt, duration, ratio, model });

  try {
    // ä½¿ç”¨image-to-videoç«¯ç‚¹
    const endpoint = '/image_to_video';
    const requestBody: any = {
      promptText: prompt,
      promptImage: imageUrl, // ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡
      model: selectModelForTask('image_to_video', model),
      ratio: validateAndFixRatioImageToVideo(ratio) // ä½¿ç”¨image-to-videoä¸“ç”¨çš„ratioéªŒè¯
    };

    // æ·»åŠ durationå‚æ•°ï¼ˆå¦‚æœæ”¯æŒï¼‰
    if (duration && (duration === 5 || duration === 10)) {
      requestBody.duration = duration;
    }

    console.log("ğŸ“¤ Sending image-to-video request:", JSON.stringify(requestBody, null, 2));

    const response = await fetchWithRetry(`${RUNWAY_API_BASE_URL}${endpoint}`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${RUNWAY_API_KEY}`,
        'Content-Type': 'application/json',
        'X-Runway-Version': '2024-11-06'
      },
      body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
      const error = await response.text();
      console.error("âŒ Runway image-to-video API error response:", error);
      throw new Error(`Runway image-to-video API failed: ${response.status} ${error}`);
    }

    const taskData = await response.json();
    console.log("ğŸ“‹ Image-to-video task created:", taskData.id);

    // ç­‰å¾…è§†é¢‘ç”Ÿæˆå®Œæˆ
    const videoResultUrl = await waitForVideoGeneration(taskData.id);
    console.log("âœ… Image-to-video generated:", videoResultUrl);

    return { url: videoResultUrl };
    
  } catch (error) {
    console.error("âŒ Failed to process image-to-video:", error);
    throw new Error(`å›¾ç‰‡è½¬è§†é¢‘å¤±è´¥: ${error instanceof Error ? error.message : String(error)}`);
  }
}